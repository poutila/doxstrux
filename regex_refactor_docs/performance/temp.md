DETAILED_TASK_TEMPLATE.md
---
title: "DETAILED TASK TEMPLATE — <PROJECT / FEATURE NAME>"
version: "1.0"
document_id: "<AUTO-GENERATED-ID>"
phase: "<PHASE_NUMBER_OR_NAME>"
created: "{{YYYY-MM-DD}}"
owner: "{{TEAM_OR_PERSON}}"
audience: ["dev","sre","security"]
---

# Phase {{PHASE}} — {{SHORT PHASE NAME}}

## One-line goal
{{ONE_LINE_GOAL}}  
(e.g. "Replace regex X with token-based extractor; keep parity and perf under budget")

---

## Metadata (must fill)
- Phase number: `{{INT}}`
- Phase unlock artifact path: `.phase-{{PHASE}}.complete.json`
- Expected corpus count env var: `CORPUS_COUNT` or computed at runtime
- MAX_ISSUES_PER_RUN / RATE LIMIT guards: `{{INT}}`
- Platform requirement: `{{Linux|Windows|Any}}` (brief justification)

---

## Preconditions / Prereqs
- Required secrets: `GITHUB_TOKEN`, `PUSHGATEWAY_URL`, `SIGNING_PUBLIC_KEY` (enumerate)
- Required CI workflows present:
  - `.github/workflows/{{PRE_MERGE_WORKFLOW}}`
  - `.github/workflows/{{ADVERSARIAL_SMOKE_WORKFLOW}}`
- Required tools installed:
  - `python3`, `jq`, `gpg`, `portalocker` (list)
- Required baseline files:
  - `tools/baseline_generation_summary.json`
  - `evidence_blocks.jsonl` (if applicable)

---

## Phase Unlock Mechanism (REQUIRED)
**Artifact schema** (.phase-{{PHASE-1}}.complete.json):
```json
{
  "phase": {{PHASE-1}},
  "completed_at": "<ISO8601>",
  "baseline_pass_count": <INT>,
  "performance_delta_median_pct": <FLOAT>,
  "ci_gates_passed": ["G1","G2","G3","G4","G5"],
  "regex_count_before": <INT>,
  "regex_count_after": <INT>,
  "git_commit": "<SHA>",
  "schema_version": "1.0",
  "min_schema_version": "1.0"
}
Enforcement (CI pre-task):

Validate .phase-{{PHASE-1}}.complete.json exists and matches schema_version and baseline_count.

If missing → fail the job.

Must-have safety guards (land before canary)
Ingest gate — validate artifact schema + HMAC if policy required.

CI snippet: python tools/validate_consumer_art.py --artifact ${ARTIFACT}

Permission check → fallback — ensure_issue_create_permissions() call before any external writes.

Digest cap + idempotency — MAX_ISSUES_PER_RUN={{INT}} and <!-- audit-id:UUID --> in issue body.

Platform/timeouts enforcement — enforce platform compatibility before running SIGALRM-based timeouts.

Minimal telemetry — counters: audit_issue_create_failures_total, audit_digest_created_total, audit_unregistered_repos_total, audit_fp_marked_total, audit_rate_limited_total.

Minimal CI gates (required)
G1 — No Hybrids (fail if mixed token/regex markers remain)

G2 — Canonical Pairs (corpus integrity)

G3 — Parity (structural output parity)

G4 — Performance (Δmedian ≤5%, Δp95 ≤10%)

G5 — Evidence Hash (validate evidence_blocks.jsonl)

Gate output policy: ALWAYS output one JSON line: {"status":"OK|FAIL|SKIP", ...}

Quick Checklist — apply in order
 Add ingest gate CI snippet

 Inject ensure_issue_create_permissions() into create-issue path

 Implement digest cap and idempotent update

 Add Linux assertion to pre-merge CI (if SIGALRM used)

 Emit minimal telemetry counters

 Wire adversarial-smoke corpus into PR checks

 Run dry-run and inspect artifacts

 Start 48-hour pilot (if all above pass)

Tasks (copy the pattern below per subtask)
TASK {{PHASE}}.{{TASK_ID}} — <SHORT TASK NAME>
Time estimate: {{HOURS}}
Files: {{FILES_TO_EDIT}}
Acceptance tests: {{TESTS_TO_RUN}}

Steps:

git checkout -b {{branch-name}}

Implement change:

code stub / pseudo-code here

Add unit tests:

tests/test_{{feature}}.py::test_xxx

Run fast tests: ./tools/run_tests_fast.sh {{subset}}

Run full baseline: python3 tools/baseline_test_runner.py --profile moderate

If tests pass → commit: git commit -m "Phase {{PHASE}}: {{SHORT MSG}}"

Create evidence block (if change significant):

echo '{"evidence_id":"phase{{PHASE}}-{{TAG}}","phase":{{PHASE}},"file":"{{file}}","lines":"{{start}}-{{end}}","description":"{{desc}}"}' \
  | python3 tools/create_evidence_block.py
Exit criteria:

Unit tests added & passing

Baseline parity holds

Performance within threshold (if applicable)

Evidence & Artifact Handling
Use tools/create_evidence_block.py (portalocker-based) for all evidence appends.

Redact sensitive snippets (utility will truncate to 1000 chars post-redaction).

Upload fallback artifacts to secure storage (GH Actions artifacts or private S3) with TTL = 7 days and restricted ACL.

Performance & Memory Checks
Use tracemalloc for memory tracking; always call tracemalloc.stop() in finally blocks.

Perf thresholds:

Δmedian ≤ 5%

Δp95 ≤ 10%

Add perf measurement in tools/ci/ci_gate_performance.py and ensure JSON-only output.

Tests to require on PRs (make mandatory)
test_ingest_gate_enforced

test_permission_fallback

test_digest_idempotent

test_rate_limit_guard

test_collector_timeout

Use mocks/monkeypatch to avoid network calls; run on Linux runners.

Rollback procedures (short)
If test/regression → git restore <file> or git reset --hard HEAD~1

Performance regression → profile (cProfile) → if fix >30min, rollback.

Emergency restore → git reset --hard phase-{{PHASE-1}}-complete

Phase Completion (generate .phase-{{PHASE}}.complete.json)
Fill required fields: phase, completed_at, baseline_pass_count, performance_delta_median_pct, ci_gates_passed, regex_count_before, regex_count_after, git_commit, schema_version, min_schema_version.

Validate artifact via tools/validate_phase_artifact.py before unlocking next phase.

Contact / Escalation
Dev lead: @{{dev_handle}}

SRE on-call: @{{sre_handle}}

Security: {{security_email}}

Template metadata (machine-friendly)
document:
  id: "{{document_id}}"
  phase: "{{phase}}"
  owner: "{{owner}}"
  version: "1.0"
checks:
  required_tests:
    - test_ingest_gate_enforced
    - test_permission_fallback
    - test_digest_idempotent
  required_counters:
    - audit_issue_create_failures_total
thresholds:
  max_issues_per_run: {{MAX_ISSUES_PER_RUN}}
  fp_rate_threshold: 0.10
  perf_median_threshold_pct: 5.0
  perf_p95_threshold_pct: 10.0

---

### Usage notes
- Copy this file and replace `{{PLACEHOLDERS}}` per phase/canary.
- Keep the runbook lean: land the five must-have guards before expanding.
- This template preserves the gating & evidence approach in your detailed plan while keeping each phase machine-verifiable. :contentReference[oaicite:1]{index=1}

If you want I can:
- produce this as a JSON/YAML "phase template" for automation, or
- generate a one-file git patch that adds `docs/DETAILED_TASK_TEMPLATE.md` into the repo.

Which format would you like next?
Sinä sanoit:
produce this as a JSON/YAML "phase template"

produce
ChatGPT sanoi:
Great — below are two machine-friendly artifacts of the phase template you asked for: one YAML and one JSON. Both are equivalent; pick whichever your automation prefers.

Save as phase_template.yaml or phase_template.json in docs/ or tools/templates/. All fields are intentionally placeholders (format: {{PLACEHOLDER}}) so your automation or a human can substitute values.

phase_template.yaml
# Phase-run template (YAGNI/KISS-ready)
# Fill placeholders before use.
document:
  id: "{{document_id}}"                     # e.g. "phase-08-warehouse"
  title: "{{title}}"                        # short title
  version: "1.0"
  phase: "{{phase_number}}"                 # integer or name
  created: "{{YYYY-MM-DD}}"
  owner: "{{team_or_person}}"               # team or owner handle
  audience:
    - dev
    - sre
    - security

metadata:
  description: "{{short_description}}"
  prerequisites:
    secrets:
      - name: "GITHUB_TOKEN"
        required: true
      - name: "SLACK_WEBHOOK"
        required: false
      - name: "PUSHGATEWAY_URL"
        required: false
    required_workflows:
      - ".github/workflows/{{PRE_MERGE_WORKFLOW}}"
      - ".github/workflows/{{ADVERSARIAL_SMOKE_WORKFLOW}}"
    required_tools:
      - python3
      - jq
      - gpg

must_have_guards:
  ingest_gate:
    description: "Validate consumer artifact schema; optionally verify HMAC when policy enabled."
    ci_commands:
      - 'python tools/validate_consumer_art.py --artifact adversarial_reports/{{ARTIFACT_FILENAME}}'
      - 'if [ "${POLICY_REQUIRE_HMAC:-}" = "true" ]; then python tools/validate_consumer_art.py --artifact adversarial_reports/{{ARTIFACT_FILENAME}} --verify-hmac || exit 3; fi'
  permission_fallback:
    description: "Ensure permission to create issues in central backlog; on failure upload sanitized artifact and exit."
    call: "ensure_issue_create_permissions(central_repo, session, artifact_path)"
  digest_cap:
    description: "When #repos > MAX_ISSUES_PER_RUN create single idempotent digest issue."
    env_defaults:
      MAX_ISSUES_PER_RUN: 10
    idempotency_marker: "<!-- audit-id:{{audit_id}} -->"
  platform_timeouts:
    description: "Enforce Linux CI runner if SIGALRM/timeouts used."
    verification_command: |
      python - <<'PY'
      import platform,sys
      if platform.system()!='Linux': sys.exit(2)
      print("Linux OK")
      PY
  telemetry:
    counters:
      - audit_unregistered_repos_total
      - audit_digest_created_total
      - audit_issue_create_failures_total
      - audit_fp_marked_total
      - audit_rate_limited_total
    critical_alert:
      name: "AuditIssueCreateFailures"
      promql: 'increase(audit_issue_create_failures_total[5m]) > 0'
      severity: "page"

ci_gates:
  - id: G1
    name: "Parity"
    description: "Structural output parity tests pass."
    verify_cmd: 'pytest -q tests/test_parity.py'
  - id: G2
    name: "Performance"
    description: "Median and p95 within thresholds."
    verify_cmd: 'python tools/ci/ci_gate_performance.py --baseline baseline.json --target results.json'
  - id: G3
    name: "Adversarial Smoke"
    description: "Run minimal adversarial smoke corpora in PR."
    verify_cmd: 'python tools/run_adversarial.py --corpus adversarial_corpora/smoke.json --report /tmp/report.json'

quick_checklist:
  ordered_tasks:
    - "Add ingest gate CI snippet (see must_have_guards.ingest_gate.ci_commands)"
    - "Inject permission_fallback call into create-issues path"
    - "Implement digest cap with idempotent create-or-update logic"
    - "Add Linux assertion to pre-merge workflow"
    - "Wire minimal telemetry counters"
    - "Add the required unit tests and make them blocking on PRs"
    - "Run ingest & dry-run workflow; inspect artifacts"

tests_required_on_prs:
  - test_ingest_gate_enforced
  - test_permission_fallback
  - test_digest_idempotent
  - test_rate_limit_guard
  - test_collector_timeout

artifacts_and_retention:
  fallback_artifacts:
    storage: "{{artifact_store}}"        # e.g. "github_actions_artifacts" or "s3://bucket/path"
    retention_days: 7
    acl: "security,sre"
  metrics_log: "adversarial_reports/metrics.log"

rollback:
  recommended_commands:
    - "kubectl rollout undo deployment/{{DEPLOYMENT_NAME}}"
    - "kubectl scale deployment/{{CANARY_DEPLOYMENT}} --replicas=0"
    - "Disable ingest workflow (remove schedule or set ENABLED=false)"
  verification:
    - "kubectl get pods -l app={{APP_LABEL}}"

usage_examples:
  create_patch: 'git checkout -b canary/{{BRANCH_NAME}} && git apply {{PATCH_FILE}} && git commit -am "phase {{phase}} canary"'
  dry_run: 'python tools/create_issues_for_unregistered_hits.py --audit adversarial_reports/{{AUDIT_JSON}} --dry-run'

template_metadata:
  schema_version: "1.0"
  generated_by: "phase_template_generator"
  example_filled: false
phase_template.json
{
  "document": {
    "id": "{{document_id}}",
    "title": "{{title}}",
    "version": "1.0",
    "phase": "{{phase_number}}",
    "created": "{{YYYY-MM-DD}}",
    "owner": "{{team_or_person}}",
    "audience": ["dev", "sre", "security"]
  },
  "metadata": {
    "description": "{{short_description}}",
    "prerequisites": {
      "secrets": [
        {"name": "GITHUB_TOKEN", "required": true},
        {"name": "SLACK_WEBHOOK", "required": false},
        {"name": "PUSHGATEWAY_URL", "required": false}
      ],
      "required_workflows": [
        ".github/workflows/{{PRE_MERGE_WORKFLOW}}",
        ".github/workflows/{{ADVERSARIAL_SMOKE_WORKFLOW}}"
      ],
      "required_tools": ["python3", "jq", "gpg"]
    }
  },
  "must_have_guards": {
    "ingest_gate": {
      "description": "Validate consumer artifact schema; optionally verify HMAC when policy enabled.",
      "ci_commands": [
        "python tools/validate_consumer_art.py --artifact adversarial_reports/{{ARTIFACT_FILENAME}}",
        "if [ \"${POLICY_REQUIRE_HMAC:-}\" = \"true\" ]; then python tools/validate_consumer_art.py --artifact adversarial_reports/{{ARTIFACT_FILENAME}} --verify-hmac || exit 3; fi"
      ]
    },
    "permission_fallback": {
      "description": "Ensure permission to create issues in central backlog; on failure upload sanitized artifact and exit.",
      "call": "ensure_issue_create_permissions(central_repo, session, artifact_path)"
    },
    "digest_cap": {
      "description": "When #repos > MAX_ISSUES_PER_RUN create single idempotent digest issue.",
      "env_defaults": {"MAX_ISSUES_PER_RUN": 10},
      "idempotency_marker": "<!-- audit-id:{{audit_id}} -->"
    },
    "platform_timeouts": {
      "description": "Enforce Linux CI runner if SIGALRM/timeouts used.",
      "verification_command": "python - <<'PY'\\nimport platform,sys\\nif platform.system()!='Linux': sys.exit(2)\\nprint(\"Linux OK\")\\nPY"
    },
    "telemetry": {
      "counters": [
        "audit_unregistered_repos_total",
        "audit_digest_created_total",
        "audit_issue_create_failures_total",
        "audit_fp_marked_total",
        "audit_rate_limited_total"
      ],
      "critical_alert": {
        "name": "AuditIssueCreateFailures",
        "promql": "increase(audit_issue_create_failures_total[5m]) > 0",
        "severity": "page"
      }
    }
  },
  "ci_gates": [
    {
      "id": "G1",
      "name": "Parity",
      "description": "Structural output parity tests pass.",
      "verify_cmd": "pytest -q tests/test_parity.py"
    },
    {
      "id": "G2",
      "name": "Performance",
      "description": "Median and p95 within thresholds.",
      "verify_cmd": "python tools/ci/ci_gate_performance.py --baseline baseline.json --target results.json"
    },
    {
      "id": "G3",
      "name": "Adversarial Smoke",
      "description": "Run minimal adversarial smoke corpora in PR.",
      "verify_cmd": "python tools/run_adversarial.py --corpus adversarial_corpora/smoke.json --report /tmp/report.json"
    }
  ],
  "quick_checklist": {
    "ordered_tasks": [
      "Add ingest gate CI snippet (see must_have_guards.ingest_gate.ci_commands)",
      "Inject permission_fallback call into create-issues path",
      "Implement digest cap with idempotent create-or-update logic",
      "Add Linux assertion to pre-merge workflow",
      "Wire minimal telemetry counters",
      "Add the required unit tests and make them blocking on PRs",
      "Run ingest & dry-run workflow; inspect artifacts"
    ]
  },
  "tests_required_on_prs": [
    "test_ingest_gate_enforced",
    "test_permission_fallback",
    "test_digest_idempotent",
    "test_rate_limit_guard",
    "test_collector_timeout"
  ],
  "artifacts_and_retention": {
    "fallback_artifacts": {
      "storage": "{{artifact_store}}",
      "retention_days": 7,
      "acl": "security,sre"
    },
    "metrics_log": "adversarial_reports/metrics.log"
  },
  "rollback": {
    "recommended_commands": [
      "kubectl rollout undo deployment/{{DEPLOYMENT_NAME}}",
      "kubectl scale deployment/{{CANARY_DEPLOYMENT}} --replicas=0",
      "Disable ingest workflow (remove schedule or set ENABLED=false)"
    ],
    "verification": ["kubectl get pods -l app={{APP_LABEL}}"]
  },
  "usage_examples": {
    "create_patch": "git checkout -b canary/{{BRANCH_NAME}} && git apply {{PATCH_FILE}} && git commit -am \"phase {{phase}} canary\"",
    "dry_run": "python tools/create_issues_for_unregistered_hits.py --audit adversarial_reports/{{AUDIT_JSON}} --dry-run"
  },
  "template_metadata": {
    "schema_version": "1.0",
    "generated_by": "phase_template_generator",
    "example_filled": false
  }
}
How to use the templates
Save one or both files into your repo, e.g. docs/phase_template.yaml and docs/phase_template.json.

Replace {{PLACEHOLDERS}} programmatically or by hand. Example replacements:

{{document_id}} → phase-08-warehouse

{{ARTIFACT_FILENAME}} → consumer_artifact.json

{{artifact_store}} → github_actions_artifacts or s3://my-bucket/path

Use your automation to:

Validate the YAML/JSON schema.

Generate a concrete RUN_TO_GREEN.md by templating and filling placeholders.

Wire the ci_gates[*].verify_cmd commands into CI jobs.

Keep the YAML as canonical source of truth and commit the filled RUN_TO_GREEN.md for reviewers.

If you want, I can now:

produce a small Python helper that renders the YAML template with a map of replacements, or

add a JSON Schema for the template so CI can validate filled phase artifacts.

Which would you like next?

Sinä sanoit:
produce a small Python helper that renders the YAML template

produce
ChatGPT sanoi:

Mietti 7s
Nice — here’s a tiny, dependency-light Python helper that renders your YAML/JSON template by substituting {{PLACEHOLDER}} tokens from a replacements file (YAML or JSON) and/or environment variables. It’s KISS, safe, and has a --strict mode to fail when any placeholders remain unresolved.

Save as tools/render_template.py and run from repo root.

tools/render_template.py
#!/usr/bin/env python3
"""
render_template.py — minimal template renderer for files with {{PLACEHOLDER}} tokens.

Features
- Replaces tokens like {{FOO}} with values from a replacements YAML/JSON file or environment variables.
- Replacements file may be YAML or JSON.
- Outputs rendered file to stdout or to a target path.
- --strict mode exits non-zero if unresolved placeholders remain.
- No external templating dependency required (no Jinja2).

Usage
    # render with replacements.yaml and write to stdout
    python tools/render_template.py --template docs/phase_template.yaml --replacements config/phase08_values.yml

    # render and write to file
    python tools/render_template.py -t docs/phase_template.yaml -r config/phase08_values.yml -o RUN_TO_GREEN.md

    # render using only environment variables, strict mode (fail if unresolved)
    POLICY_REQUIRE_HMAC=true python tools/render_template.py -t docs/phase_template.yaml --strict

Replacements file examples (YAML or JSON):
    document_id: "phase-08-warehouse"
    title: "Phase 8 Warehouse"
    phase_number: 8
    ARTIFACT_FILENAME: "consumer_artifact.json"

Notes
- Token names are alphanumeric and may contain underscores: {{MY_TOKEN}}
- Environment variables take precedence if a key exists in both env and replacements file.
"""
from __future__ import annotations
import argparse
import json
import os
import re
import sys
from pathlib import Path

# Try to import yaml, but gracefully degrade to JSON-only if not present.
try:
    import yaml  # PyYAML
    _HAS_YAML = True
except Exception:
    _HAS_YAML = False

TOKEN_RE = re.compile(r"\{\{\s*([A-Za-z0-9_./:-]+)\s*\}\}")  # allow dots/slashes/colons for some keys


def load_replacements(path: Path | None) -> dict:
    if path is None:
        return {}
    txt = path.read_text(encoding="utf8")
    # Try JSON first (fast), then YAML if available
    try:
        data = json.loads(txt)
        if not isinstance(data, dict):
            raise ValueError("replacements JSON must be an object/dict at top-level")
        return data
    except Exception:
        if _HAS_YAML:
            try:
                data = yaml.safe_load(txt)
                if data is None:
                    return {}
                if not isinstance(data, dict):
                    raise ValueError("replacements YAML must be a mapping at top-level")
                return data
            except Exception as e:
                raise RuntimeError(f"Failed to parse replacements file as YAML/JSON: {e}")
        else:
            raise RuntimeError("Replacements file is not valid JSON and PyYAML not installed to parse YAML.")


def render_template(template_text: str, context: dict, strict: bool = False) -> str:
    """
    Replace tokens in template_text with context values. context keys and env vars are strings.
    If strict=True, raise a RuntimeError when unresolved placeholders remain.
    """
    def repl(m: re.Match):
        key = m.group(1)
        if key in context:
            return str(context[key])
        # allow nested keys via dot lookup: a.b -> context['a']['b'] if dict-like
        if "." in key:
            parts = key.split(".")
            cur = context
            for p in parts:
                if isinstance(cur, dict) and p in cur:
                    cur = cur[p]
                else:
                    cur = None
                    break
            if cur is not None:
                return str(cur)
        # fallback to environment
        env_val = os.environ.get(key)
        if env_val is not None:
            return env_val
        # unresolved -> keep token or raise later
        return m.group(0)

    rendered = TOKEN_RE.sub(repl, template_text)

    # if strict mode, detect unresolved tokens
    if strict:
        unresolved = TOKEN_RE.findall(rendered)
        if unresolved:
            raise RuntimeError(f"Unresolved placeholders after rendering (strict mode): {sorted(set(unresolved))}")
    return rendered


def find_placeholders(template_text: str) -> list:
    return sorted(set(TOKEN_RE.findall(template_text)))


def main(argv: list[str] | None = None) -> int:
    p = argparse.ArgumentParser(prog="render_template.py", description="Render {{PLACEHOLDER}} tokens in a template file.")
    p.add_argument("-t", "--template", required=True, help="Path to template file (YAML/MD/JSON/etc.)")
    p.add_argument("-r", "--replacements", required=False, help="Path to replacements file (YAML or JSON)")
    p.add_argument("-o", "--output", required=False, help="Output path; if omitted prints to stdout")
    p.add_argument("--strict", action="store_true", help="Fail if any placeholders remain unresolved")
    p.add_argument("--list-placeholders", action="store_true", help="Only list placeholders found in template and exit 0")
    args = p.parse_args(argv)

    tpl_path = Path(args.template)
    if not tpl_path.exists():
        print(f"ERROR: template not found: {tpl_path}", file=sys.stderr)
        return 2

    repl_path = Path(args.replacements) if args.replacements else None
    try:
        replacements = load_replacements(repl_path) if repl_path else {}
    except Exception as e:
        print(f"ERROR: failed to load replacements: {e}", file=sys.stderr)
        return 3

    # environment variables override replacements file
    env_context = {k: v for k, v in os.environ.items()}
    # Merge: env takes precedence
    context = {**replacements, **env_context}

    template_text = tpl_path.read_text(encoding="utf8")

    if args.list_placeholders:
        placeholders = find_placeholders(template_text)
        for ph in placeholders:
            print(ph)
        return 0

    try:
        out_text = render_template(template_text, context, strict=args.strict)
    except Exception as e:
        print(f"ERROR: rendering failed: {e}", file=sys.stderr)
        return 4

    if args.output:
        out_path = Path(args.output)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(out_text, encoding="utf8")
        print(f"Wrote rendered template to: {out_path}")
    else:
        sys.stdout.write(out_text)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
Quick examples
Render using replacements.yaml and print:

python tools/render_template.py -t docs/phase_template.yaml -r config/phase08_values.yml
Render using only environment variables (strict):

GITHUB_TOKEN=xxx POLICY_REQUIRE_HMAC=true python tools/render_template.py -t docs/phase_template.yaml --strict -o RUN_TO_GREEN.md
List placeholders in a template (useful in CI to verify all keys provided):

python tools/render_template.py -t docs/phase_template.yaml --list-placeholders
Notes & recommendations (KISS-friendly)
The helper intentionally avoids heavy templating libraries so it runs in minimal environments. If you prefer richer features (loops, conditionals), adopt Jinja2 later.

Use --strict in CI to ensure a template has all required replacements — the job will fail fast with a helpful list.

Prefer a small replacements YAML for each phase (e.g. values/phase-08.yaml) and keep it out of version control if it contains secrets. Use CI secrets for sensitive values (the script will read environment variables).
