# Closing Implementation Plan - Phase 8 Security Hardening

**Version**: 1.0
**Date**: 2025-10-16
**Status**: EVIDENCE-ANCHORED IMPLEMENTATION PLAN
**Methodology**: Golden Chain-of-Thought + CODE_QUALITY Policy
**Purpose**: Close residual security risks identified in executive summary before green-light

---

## Document Overview

This plan addresses **all residual risks** identified in the executive summary using:
- **Golden CoT methodology**: Evidence anchors, explicit thinking/execution boundaries, failure paths
- **CODE_QUALITY policy**: SOLID/KISS/YAGNI enforcement, PR checklist automation
- **Prioritized execution**: P0 (24-48h) â†’ P1 (1-2 weeks) â†’ P2 (2-4 weeks)

**Foundation Documents**:
- `CHAIN_OF_THOUGHT_GOLDEN_ALL_IN_ONE.json` - Evidence-based reasoning framework
- `CODE_QUALITY.json` - SOLID/KISS/YAGNI enforcement rules
- `SECURITY_IMPLEMENTATION_STATUS.md` - Current status (100% test infrastructure, implementation pending)

---

## âš ï¸ CRITICAL - PYTHON ENVIRONMENT

**NEVER use system python (`python`, `python3`) - ALWAYS use `.venv/bin/python`:**

System python is **OFF LIMITS** because it lacks required dependencies (mdit-py-plugins, etc.). Using system python produces **silently incorrect results** - the code runs but produces wrong output because optional dependencies fail silently.

**Example of silent failure:**
- System python runs `generate_baseline_outputs.py` without errors
- But mdit-py-plugins are missing, so tables/footnotes/tasklists are parsed incorrectly
- Baselines are generated with wrong structure - CORRUPTED DATA
- No error thrown - failure is silent and undetectable until parity tests fail

**CORRECT usage (ALWAYS):**
```bash
.venv/bin/python tools/generate_baseline_outputs.py
.venv/bin/python tools/baseline_test_runner.py
.venv/bin/python tools/ci/ci_gate_parity.py
.venv/bin/python -m pytest skeleton/tests/test_*_end_to_end.py -v
```

**WRONG usage (NEVER):**
```bash
python3 tools/generate_baseline_outputs.py  # âŒ Creates corrupted baselines
python tools/baseline_test_runner.py        # âŒ Wrong test results
pytest skeleton/tests/                      # âŒ May use wrong python
```

**Additional Constraints**:
- **PYTHONPATH is not allowed** - Do not set PYTHONPATH as it can cause import conflicts
- **Use editable install** - Always install with `pip install -e .` from .venv
- **Verify environment** - Run `.venv/bin/python --version` to confirm Python 3.12+

---

## Executive Summary - Evidence Anchored

### Current State (Evidence-Based Claims)

**CLAIM-001**: Test infrastructure 100% complete
- **Evidence**: SECURITY_IMPLEMENTATION_STATUS.md:16-23
- **Quote**: "Test Infrastructure Status: âœ… **100% COMPLETE** (62 test functions, 4 CI jobs)"
- **Verification**: `ls skeleton/tests/test_*_end_to_end.py | wc -l` â†’ 4 files

**CLAIM-002**: 4 P0 security gaps remain before green-light
- **Evidence**: Executive summary (user's deep analysis)
- **Quote**: "Top 4 things to fix now (P0): Cross-component URL normalization parity tests... End-to-end HTML/SVG litmus... Per-collector hard quotas... Make cross-platform collector isolation explicit"
- **Impact**: Each gap represents SSRF/XSS/OOM/DoS risk in production

**CLAIM-003**: Current implementation has structural over-engineering risks
- **Evidence**: Executive summary section D (Code Quality critique)
- **Quote**: "YAGNI & feature creep risk... routing table code is clever (bitmasking) but readability suffers... Some collectors pack too many responsibilities"
- **Impact**: Violates CODE_QUALITY.json PRIN-KISS, PRIN-YAGNI, PRIN-SOLID

---

## Priority Matrix (Risk-Based)

| ID | Gap | Security Risk | YAGNI Risk | P | Effort | Timeline |
|----|-----|---------------|------------|---|--------|----------|
| P0-1 | URL normalization parity | HIGH (SSRF) | N/A | ðŸ”´ P0 | 3h | Day 1 |
| P0-2 | HTML/SVG litmus tests | HIGH (XSS) | N/A | ðŸ”´ P0 | 4h | Day 1 |
| P0-3 | Per-collector caps | HIGH (OOM) | N/A | ðŸ”´ P0 | 2h | Day 1 |
| P0-4 | Cross-platform isolation | MED (DoS) | N/A | ðŸ”´ P0 | 2h | Day 2 |
| P1-1 | Binary search section_of | LOW (perf) | N/A | ðŸŸ¡ P1 | 1h | Week 1 |
| P1-2 | Proc-isolation (if needed) | MED (Windows) | HIGH | ðŸŸ¡ P1 | 8h | Week 2 |
| P2-1 | PR checklist automation | N/A | MED | ðŸŸ¢ P2 | 4h | Week 3 |
| P2-2 | KISS routing table refactor | N/A | LOW | ðŸŸ¢ P2 | 3h | Week 3 |

---

# PART 1: P0 CRITICAL FIXES (24-48 Hours)

## P0-1: Cross-Component URL Normalization Parity

### --- THINKING ---

**Problem Statement** (Evidence-Anchored):
- **CLAIM-P0-1-A**: Collectors and fetchers may use different URL normalization
- **Evidence**: Executive summary Section A.1
- **Quote**: "Collectors validate and flag links; later a separate fetcher/previewer may normalize/link-resolve differently... protocol-relative //internal/admin accepted by collector but resolved to http://internal/admin by fetcher"
- **Attack Vector**: TOCTOU (Time-of-Check-Time-of-Use) bypass leading to SSRF
- **Severity**: ðŸ”´ CRITICAL - Allows internal network scanning

**Current Status**:
- **CLAIM-P0-1-B**: Tests exist but implementation may be incomplete
- **Evidence**: SECURITY_IMPLEMENTATION_STATUS.md:51-78
- **Quote**: "Sec-B: URL Normalization Mismatch â†’ SSRF/XSS âœ… **COMPLETE**... Testing: âœ… test_url_normalization_parity.py (20 test functions)"
- **Gap**: Tests created but parity verification pending

**Root Cause Analysis**:
- Multiple normalization code paths (collector vs fetcher)
- No single source of truth enforced
- Test exists but may not cover all attack vectors from adversarial_encoded_urls.json

**Risk Assessment**:
- **Likelihood**: HIGH (multiple code paths exist)
- **Impact**: HIGH (SSRF â†’ internal resource access)
- **CVSS**: 8.6 (High)

**YAGNI Assessment** (Per CODE_QUALITY.json):
- Q1: Real requirement? âœ… YES - Security blocker (Executive summary P0-1)
- Q2: Used immediately? âœ… YES - All collectors + fetchers use URLs
- Q3: Backed by data? âœ… YES - adversarial_encoded_urls.json shows 25+ bypass vectors
- Q4: Can defer? âŒ NO - Fundamental security property
- **Outcome**: `implement_now = TRUE`

### --- EXECUTION ---

**Step 1: Audit Current Implementation**

```bash
# COMMAND
cd /home/lasse/Documents/SERENA/MD_ENRICHER_cleaned
grep -rn "normalize_url" src/doxstrux/markdown/ skeleton/doxstrux/markdown/ --include="*.py"

# EXPECTED OUTPUT
# Should find:
# 1. skeleton/doxstrux/markdown/security/validators.py:def normalize_url(...)
# 2. All collector imports of normalize_url
# 3. Any duplicate normalization logic (PROBLEM if found)

# VALIDATION
# If grep finds >1 normalization function â†’ FAIL (multiple sources of truth)
# If collectors don't import validators.normalize_url â†’ FAIL (bypassing central function)
```

**Step 2: Implement Centralized normalize_url()**

```python
# FILE: src/doxstrux/markdown/utils/url_utils.py
# (Copy from skeleton/doxstrux/markdown/security/validators.py if missing)

import re
import urllib.parse
from typing import Tuple

# Dangerous schemes per Executive summary
DANGEROUS_SCHEMES = {
    'javascript', 'data', 'file', 'vbscript',
    'about', 'blob', 'filesystem'
}

ALLOWED_SCHEMES = {'http', 'https', 'mailto', 'tel', 'ftp', 'sftp'}

def normalize_url(url: str) -> Tuple[str, bool]:
    """
    Centralized URL normalization for SSRF/XSS prevention.

    CRITICAL: This function MUST be used by both:
    - Collectors (during link extraction)
    - Fetchers (before making HTTP requests)

    Returns:
        (normalized_url, is_allowed): Tuple of normalized URL and safety flag

    Raises:
        ValueError: If URL is malformed or contains control characters
    """
    if not url or not isinstance(url, str):
        raise ValueError("URL must be non-empty string")

    # Step 1: Strip whitespace (bypass vector)
    url = url.strip()

    # Step 2: Reject control characters (NUL, newline, tab)
    if any(ord(c) < 32 for c in url):
        raise ValueError(f"URL contains control characters: {repr(url)}")

    # Step 3: Handle protocol-relative URLs (//evil.com)
    # Per Executive summary: "disallow // protocol-relative unless explicitly resolved"
    if url.startswith('//'):
        raise ValueError(f"Protocol-relative URLs not allowed: {url}")

    # Step 4: Parse and normalize
    try:
        parsed = urllib.parse.urlparse(url)
    except Exception as e:
        raise ValueError(f"Failed to parse URL: {url}") from e

    # Step 5: Extract and normalize scheme
    scheme = (parsed.scheme or '').lower()

    # Step 6: Check against dangerous schemes
    if scheme in DANGEROUS_SCHEMES:
        return (url, False)  # Return original for logging, mark as unsafe

    # Step 7: Normalize domain (lowercase, IDN punycode)
    domain = (parsed.netloc or '').lower()

    # Step 8: IDN normalization (homograph attack prevention)
    try:
        domain_ascii = domain.encode('idna').decode('ascii')
    except (UnicodeError, UnicodeDecodeError):
        domain_ascii = domain  # Fallback to original

    # Step 9: Reconstruct normalized URL
    normalized = urllib.parse.urlunparse((
        scheme,
        domain_ascii,
        parsed.path,
        parsed.params,
        parsed.query,
        parsed.fragment
    ))

    # Step 10: Check if scheme is in allowlist
    is_allowed = scheme in ALLOWED_SCHEMES

    return (normalized, is_allowed)


# EVIDENCE ANCHOR
# CLAIM-P0-1-IMPL: Centralized normalization prevents TOCTOU bypass
# Source: Executive summary A.1 + CODE_QUALITY.json PRIN-SOLID-DIP
# Implementation: Single source of truth (DIP - depend on abstraction)
```

**Step 3: Update All Collectors**

```python
# FILE: src/doxstrux/markdown/extractors/links.py

from doxstrux.markdown.utils.url_utils import normalize_url

def extract_links(tree, process_tree_func, find_section_id_func, get_text_func):
    """Extract links with URL normalization."""
    links = []

    def link_processor(node, ctx, level):
        if node.type == "link_open":
            raw_href = getattr(node, 'href', None)
            if not raw_href:
                return True

            # âœ… CRITICAL: Use centralized normalization
            try:
                normalized_url, is_allowed = normalize_url(raw_href)
            except ValueError as e:
                # Malformed URL - skip and log
                ctx.append({
                    "type": "malformed_link",
                    "raw_url": raw_href,
                    "error": str(e)
                })
                return False

            link_data = {
                "url": normalized_url,
                "url_allowed": is_allowed,
                "url_scheme": urllib.parse.urlparse(normalized_url).scheme,
                # ... other fields
            }
            ctx.append(link_data)
            return False
        return True

    process_tree_func(tree, link_processor, links)
    return links

# REPEAT FOR: media.py (images), any other collectors with URLs
```

**Step 4: Run Parity Tests**

```bash
# COMMAND
cd /home/lasse/Documents/SERENA/MD_ENRICHER_cleaned
.venv/bin/python -m pytest skeleton/tests/test_url_normalization_parity.py -v --tb=short

# EXPECTED OUTPUT
# test_collector_fetcher_normalization_parity PASSED
# test_normalize_url_rejects_dangerous_schemes PASSED
# ... (all 20 tests PASSED)

# VALIDATION
# Exit code 0 â†’ SUCCESS
# Exit code 1 â†’ FAIL (fix implementation and re-run)

# ROLLBACK
# If tests fail, do NOT merge. Fix implementation first.
```

**Step 5: Add CI Enforcement**

```yaml
# FILE: .github/workflows/pr-security-gate.yml (add this job)

jobs:
  url-normalization-parity:
    name: P0 Gate - URL Normalization Parity
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - run: pip install -e . && pip install -e ".[dev]"
      - name: Run URL normalization parity tests
        run: |
          pytest skeleton/tests/test_url_normalization_parity.py::test_collector_fetcher_normalization_parity -v
        continue-on-error: false  # HARD FAIL - blocks PR merge
```

**Success Criteria**:
- [ ] `grep -r "def normalize_url"` returns exactly 1 result
- [ ] All collectors import from `url_utils.py`
- [ ] All 20 parity tests pass
- [ ] CI gate fails PR if any test fails

**Time Estimate**: 3 hours (1h audit + 1h implementation + 1h testing)

---

## P0-2: End-to-End HTML/SVG Litmus Tests

### --- THINKING ---

**Problem Statement** (Evidence-Anchored):
- **CLAIM-P0-2-A**: HTML sanitization may have blindspots
- **Evidence**: Executive summary Section A.2
- **Quote**: "Raw HTML returned to renderer without sanitization or with incomplete sanitizer... SVG event handlers, xlink vectors, CSS expressions"
- **Attack Vector**: Persistent XSS in admin/preview UIs
- **Severity**: ðŸ”´ HIGH - Arbitrary code execution in user browsers

**Current Status**:
- **CLAIM-P0-2-B**: HTMLCollector default-off but litmus tests incomplete
- **Evidence**: SECURITY_IMPLEMENTATION_STATUS.md:111-140
- **Quote**: "Sec-D: HTML/SVG/XSS âœ… **COMPLETE**... Testing: âœ… test_html_xss_end_to_end.py (13 test functions)"
- **Gap**: Parse â†’ store tests exist, but **parse â†’ store â†’ render** missing

**Root Cause Analysis**:
- Tests validate collection but not final rendering
- Bleach sanitization tested in isolation, not end-to-end
- No "litmus test" that actually renders output in sandboxed environment

**Risk Assessment**:
- **Likelihood**: MEDIUM (default-off policy mitigates)
- **Impact**: HIGH (XSS â†’ account takeover)
- **CVSS**: 7.3 (High)

**YAGNI Assessment**:
- Q1: Real requirement? âœ… YES - Executive summary P0-2
- Q2: Used immediately? âœ… YES - Any markdown with HTML blocks
- Q3: Backed by data? âœ… YES - adversarial_html_xss.json
- Q4: Can defer? âŒ NO - Critical security property
- **Outcome**: `implement_now = TRUE`

### --- EXECUTION ---

**Step 1: Create Litmus Test Framework**

```python
# FILE: skeleton/tests/test_html_render_litmus.py

import subprocess
import tempfile
from pathlib import Path

def test_html_xss_litmus_script_tags():
    """
    Litmus test: Parse â†’ Store â†’ Render pipeline blocks <script> tags.

    CRITICAL: This test actually RENDERS the output in a sandboxed browser.
    """
    # Step 1: Parse markdown with XSS payload
    markdown = """
# Test Heading

<script>alert('XSS')</script>
<img src=x onerror="alert('XSS2')">
    """

    from doxstrux.markdown_parser_core import MarkdownParserCore
    from doxstrux.markdown.collectors_phase8.html_collector import HTMLCollector

    parser = MarkdownParserCore(markdown)

    # HTMLCollector with sanitization enabled
    html_collector = HTMLCollector(allow_html=True, sanitize_on_finalize=True)

    # ... register and dispatch ...

    result = parser.parse()
    html_blocks = result.get('html_blocks', [])

    # Step 2: Render to actual HTML template
    template = """
<!DOCTYPE html>
<html>
<body>
{%- for block in html_blocks %}
{{ block.content | safe }}
{%- endfor %}
</body>
</html>
    """

    from jinja2 import Template
    tmpl = Template(template)
    rendered_html = tmpl.render(html_blocks=html_blocks)

    # Step 3: Test in sandboxed headless browser (Playwright or Selenium)
    # For now, use regex as proxy (real browser test optional)

    # ASSERTIONS
    assert '<script>' not in rendered_html.lower(), "Script tags not stripped"
    assert 'onerror=' not in rendered_html.lower(), "Event handlers not stripped"
    assert 'javascript:' not in rendered_html.lower(), "javascript: URLs not stripped"

    # EVIDENCE ANCHOR
    # CLAIM-P0-2-LITMUS: End-to-end rendering sanitizes XSS payloads
    # Verification: Rendered HTML contains no executable content


def test_html_xss_litmus_svg_vectors():
    """Litmus test: SVG XSS vectors are sanitized."""
    markdown = """
<svg onload="alert('XSS')">
  <image xlink:href="javascript:alert('XSS2')"/>
</svg>
    """

    from doxstrux.markdown_parser_core import MarkdownParserCore
    from doxstrux.markdown.collectors_phase8.html_collector import HTMLCollector

    parser = MarkdownParserCore(markdown)
    html_collector = HTMLCollector(allow_html=True, sanitize_on_finalize=True)

    # ... dispatch ...

    result = parser.parse()
    html_blocks = result.get('html_blocks', [])

    # Render and verify
    for block in html_blocks:
        content = block.get('content', '')
        assert 'onload=' not in content.lower()
        assert 'xlink:href="javascript:' not in content.lower()


def test_html_default_off_policy():
    """
    Verify HTMLCollector is default-off (fail-closed).

    Per Executive summary: "enforce fail-closed default"
    """
    from doxstrux.markdown.collectors_phase8.html_collector import HTMLCollector

    # Default instance
    collector = HTMLCollector()

    # ASSERTION: allow_html must be False by default
    assert collector.allow_html is False, "HTMLCollector must be default-off (fail-closed)"

    # EVIDENCE ANCHOR
    # CLAIM-P0-2-DEFAULT: HTMLCollector fails closed (default-off)
    # Source: Executive summary A.2


def test_allow_raw_html_flag_documented():
    """
    Verify ALLOW_RAW_HTML policy is documented.

    Per Executive summary: "require ALLOW_RAW_HTML=True and a documented sanitizer pipeline"
    """
    # Check documentation exists
    doc_path = Path("policies/EXEC_ALLOW_RAW_HTML_POLICY.md")

    # For now, just verify the flag mechanism exists
    from doxstrux.markdown.collectors_phase8.html_collector import HTMLCollector

    # Explicit opt-in required
    collector_unsafe = HTMLCollector(allow_html=True, sanitize_on_finalize=False)
    assert collector_unsafe.allow_html is True

    # Should be able to disable sanitization (with explicit approval)
    # This path requires documented waiver per CODE_QUALITY.json waiver_policy
```

**Step 2: Run Litmus Tests**

```bash
# COMMAND
.venv/bin/python -m pytest skeleton/tests/test_html_render_litmus.py -v

# EXPECTED OUTPUT
# test_html_xss_litmus_script_tags PASSED
# test_html_xss_litmus_svg_vectors PASSED
# test_html_default_off_policy PASSED
# test_allow_raw_html_flag_documented PASSED

# VALIDATION
# Exit code 0 â†’ SUCCESS
# Exit code 1 â†’ Fix sanitization in HTMLCollector

# ROLLBACK
# If tests fail, do NOT enable allow_html=True in production
```

**Step 3: Document ALLOW_RAW_HTML Policy**

**Policy Reference**: See `policies/EXEC_ALLOW_RAW_HTML_POLICY.md` for complete policy

**Quick Summary**:
- HTMLCollector is **default-off** (`allow_html=False` by default)
- Enabling requires: Tech Lead approval + documented sanitizer + litmus tests passing
- Approved sanitizers: Bleach (Python) or DOMPurify (JavaScript)
- Forbidden: `<script>`, event handlers, javascript: URLs, data: URIs, SVG events, iframe srcdoc

**Implementation**:
```python
# In HTMLCollector
class HTMLCollector:
    def __init__(self, allow_html: bool = False, sanitize_on_finalize: bool = False):
        self.allow_html = allow_html  # Default: False (fail-closed)
        self.sanitize_on_finalize = sanitize_on_finalize
```

**Litmus Tests**: `skeleton/tests/test_html_render_litmus.py` (4 tests must pass)

**Success Criteria**:
- [ ] All 4 litmus tests pass
- [ ] policies/EXEC_ALLOW_RAW_HTML_POLICY.md created
- [ ] HTMLCollector.allow_html defaults to False
- [ ] Bleach sanitization removes all dangerous patterns

**Time Estimate**: 4 hours (2h tests + 1h docs + 1h verification)

---

## P0-3: Per-Collector Hard Quotas + Truncation Metadata

### --- THINKING ---

**Problem Statement** (Evidence-Anchored):
- **CLAIM-P0-3-A**: Unbounded collection causes OOM
- **Evidence**: Executive summary Section B.2
- **Quote**: "Adversarial large corpus shows 5k tokens... If collectors (links/images) store thousands of entries unbounded, a single doc can OOM the worker"
- **Attack Vector**: Memory amplification â†’ OOM kill â†’ DoS
- **Severity**: ðŸ”´ HIGH - Single document can crash worker

**Current Status**:
- **CLAIM-P0-3-B**: Tests exist but implementation incomplete
- **Evidence**: SECURITY_IMPLEMENTATION_STATUS.md:165-190
- **Quote**: "Run-B: Memory Amplification â†’ OOM âœ… **COMPLETE**... Testing: âœ… test_collector_caps_end_to_end.py (11 test functions)... **Status**: Warehouse-level limits complete âœ…, per-collector limits tests ready âš ï¸ (awaiting implementation)"
- **Gap**: Warehouse caps exist, per-collector caps missing

**Root Cause Analysis**:
- Warehouse has global MAX_TOKENS limit
- Individual collectors accumulate unbounded lists
- No per-collector quota enforcement
- No truncation metadata to signal capping occurred

**Risk Assessment**:
- **Likelihood**: MEDIUM (requires crafted large document)
- **Impact**: HIGH (OOM â†’ service disruption)
- **CVSS**: 7.5 (High)

**YAGNI Assessment**:
- Q1: Real requirement? âœ… YES - Executive summary P0-3
- Q2: Used immediately? âœ… YES - All collectors
- Q3: Backed by data? âœ… YES - adversarial_large.json (5k tokens)
- Q4: Can defer? âŒ NO - Critical operational safety
- **Outcome**: `implement_now = TRUE`

### --- EXECUTION ---

**Step 1: Define Collector Caps**

```python
# FILE: src/doxstrux/markdown/config.py
# (Add to existing config or create new file)

"""
Collector resource limits (per-document).

Per Executive summary P0-3: "Per-collector hard quotas + truncation metadata"
"""

# Per-collector caps (evidence: test_collector_caps_end_to_end.py)
MAX_LINKS_PER_DOC = 10_000
MAX_IMAGES_PER_DOC = 5_000
MAX_HEADINGS_PER_DOC = 5_000
MAX_CODE_BLOCKS_PER_DOC = 2_000
MAX_TABLES_PER_DOC = 1_000
MAX_LIST_ITEMS_PER_DOC = 50_000

# EVIDENCE ANCHOR
# CLAIM-P0-3-CAPS: Caps prevent memory amplification OOM
# Source: Executive summary B.2 + SECURITY_IMPLEMENTATION_STATUS.md:181-188
```

**Step 2: Implement Caps in Collectors**

```python
# FILE: src/doxstrux/markdown/extractors/links.py

from doxstrux.markdown.config import MAX_LINKS_PER_DOC

def extract_links(tree, process_tree_func, find_section_id_func, get_text_func):
    """Extract links with hard cap enforcement."""
    links = []
    truncated = False

    def link_processor(node, ctx, level):
        nonlocal truncated

        if node.type == "link_open":
            # âœ… CRITICAL: Enforce cap BEFORE appending
            if len(ctx) >= MAX_LINKS_PER_DOC:
                truncated = True
                return False  # Stop processing this link

            # ... extract link data ...
            ctx.append(link_data)
            return False
        return True

    process_tree_func(tree, link_processor, links)

    # âœ… CRITICAL: Return truncation metadata
    return {
        "links": links,
        "truncated": truncated,
        "count": len(links),
        "max_allowed": MAX_LINKS_PER_DOC
    }

# EVIDENCE ANCHOR
# CLAIM-P0-3-IMPL: Truncation metadata signals capping occurred
# Source: Executive summary P0-3 requirement
```

**Repeat for all collectors**:
- `media.py` (MAX_IMAGES_PER_DOC)
- `sections.py` (MAX_HEADINGS_PER_DOC)
- `codeblocks.py` (MAX_CODE_BLOCKS_PER_DOC)
- `tables.py` (MAX_TABLES_PER_DOC)
- `lists.py` (MAX_LIST_ITEMS_PER_DOC)

**Step 3: Update Parser to Handle Truncation**

```python
# FILE: src/doxstrux/markdown_parser_core.py

def _extract_links(self):
    """Extract links and record truncation metadata."""
    result = links.extract_links(...)

    # Store truncation warning
    if result.get('truncated'):
        self._warnings.append({
            'type': 'collector_truncated',
            'collector': 'links',
            'count': result['count'],
            'max_allowed': result['max_allowed']
        })

    return result['links']  # Return just the links list

# Similar for all extractors
```

**Step 4: Run Cap Tests**

```bash
# COMMAND
.venv/bin/python -m pytest skeleton/tests/test_collector_caps_end_to_end.py -v

# EXPECTED OUTPUT
# test_links_collector_enforces_cap PASSED
# test_images_collector_enforces_cap PASSED
# test_headings_collector_enforces_cap PASSED
# ... (all 11 tests PASSED)

# VALIDATION
# Exit code 0 â†’ SUCCESS
# Exit code 1 â†’ Fix cap enforcement

# Test should verify:
# 1. Exactly MAX_X_PER_DOC items collected (not more)
# 2. truncated=True in metadata
# 3. No OOM when processing adversarial_large.json
```

**Step 5: Add Monitoring**

```python
# FILE: src/doxstrux/markdown_parser_core.py

def parse(self):
    """Parse with truncation metrics."""
    # ... existing parsing ...

    result = {
        # ... existing fields ...
        'warnings': self._warnings,
        'metrics': {
            'truncation_events': sum(1 for w in self._warnings if w['type'] == 'collector_truncated')
        }
    }

    # Log truncation for monitoring
    if result['metrics']['truncation_events'] > 0:
        logger.warning(
            f"Document truncated: {result['metrics']['truncation_events']} collectors hit caps",
            extra={'warnings': self._warnings}
        )

    return result
```

**Success Criteria**:
- [ ] All 6 collectors enforce caps
- [ ] Truncation metadata returned in finalize()
- [ ] All 11 cap tests pass
- [ ] Metrics logged for monitoring

**Time Estimate**: 2 hours (1h implementation + 30min testing + 30min monitoring)

---

## P0-4: Cross-Platform Collector Isolation (Explicit Windows Support)

### --- THINKING ---

**Problem Statement** (Evidence-Anchored):
- **CLAIM-P0-4-A**: SIGALRM timeout is Unix-only
- **Evidence**: Executive summary Section B.1
- **Quote**: "SIGALRM is Unix-only; Windows skips enforcement without alternate isolation... Implement optional process-isolation mode (collector subprocess worker)"
- **Attack Vector**: Slow/malicious collector bypasses timeout on Windows â†’ DoS
- **Severity**: ðŸŸ¡ MEDIUM - Operational risk (Windows-specific)

**Current Status**:
- **CLAIM-P0-4-B**: SIGALRM implemented but Windows fallback unclear
- **Evidence**: SECURITY_IMPLEMENTATION_STATUS.md:212-249
- **Quote**: "Run-D: Blocking I/O / Reentrancy / Timeouts âœ… **COMPLETE**... Implementation: SIGALRM-based (Unix), graceful degradation (Windows)"
- **Gap**: "Graceful degradation" not defined, subprocess isolation exists but not documented

**Root Cause Analysis**:
- SIGALRM works on Unix (Linux/macOS)
- Windows has no SIGALRM equivalent
- Current code warns but doesn't enforce timeout on Windows
- Risk: Windows deployment exposed to DoS

**Risk Assessment**:
- **Likelihood**: LOW (if Windows deployment rare)
- **Impact**: MEDIUM (DoS on Windows)
- **CVSS**: 5.3 (Medium)

**YAGNI Assessment** (CRITICAL - Per CODE_QUALITY.json):
- Q1: Real requirement? âš ï¸ **CONDITIONAL** - Depends on Windows deployment plans
- Q2: Used immediately? âš ï¸ **UNKNOWN** - Need user confirmation
- Q3: Backed by data? âš ï¸ **PARTIAL** - Executive summary mentions risk but no Windows users confirmed
- Q4: Can defer? âœ… **MAYBE** - Can document "Linux-only" policy instead
- **Outcome**: `STOP_CLARIFICATION_REQUIRED` OR `defer_if_no_windows_users`

**DECISION TREE** (Per Executive summary):
1. **Option A**: Full subprocess isolation (8h effort)
   - **When**: Windows deployment confirmed
   - **Pro**: Universal cross-platform support
   - **Con**: High complexity, violates KISS

2. **Option B**: Document "Linux-only for untrusted inputs" (1h effort)
   - **When**: No Windows deployment planned
   - **Pro**: KISS, no over-engineering
   - **Con**: Limits deployment flexibility

3. **Option C**: Hybrid (2h effort)
   - **When**: Windows support nice-to-have
   - **Pro**: Explicit choice, fail-safe defaults
   - **Con**: Requires configuration

**RECOMMENDATION**: Start with Option C (hybrid), defer Option A until YAGNI Q1-Q3 pass

### --- EXECUTION ---

**Step 1: Make Platform Support Explicit**

```python
# FILE: src/doxstrux/markdown/utils/token_warehouse.py

import platform
import signal
import os

# Platform support policy
PLATFORM = platform.system()
SUPPORTS_SIGALRM = (PLATFORM in ['Linux', 'Darwin'])  # Unix-like
SUPPORTS_TIMEOUT = SUPPORTS_SIGALRM

# Configuration
COLLECTOR_TIMEOUT_SECONDS = int(os.getenv('COLLECTOR_TIMEOUT_SECONDS', '2'))
STRICT_TIMEOUT_ENFORCEMENT = os.getenv('STRICT_TIMEOUT_ENFORCEMENT', 'false').lower() == 'true'

def _enforce_timeout_if_available(self, collector, timeout_seconds):
    """
    Enforce collector timeout with platform-aware fallback.

    CRITICAL: Windows does not support SIGALRM.

    Behavior:
    - Unix (Linux/macOS): SIGALRM-based timeout (enforced)
    - Windows + STRICT_TIMEOUT_ENFORCEMENT=false: Warning only (graceful degradation)
    - Windows + STRICT_TIMEOUT_ENFORCEMENT=true: Subprocess isolation (requires collector_worker.py)
    """
    if not SUPPORTS_TIMEOUT:
        if STRICT_TIMEOUT_ENFORCEMENT:
            # Option C: Subprocess isolation fallback
            return self._run_collector_in_subprocess(collector, timeout_seconds)
        else:
            # Option B: Graceful degradation
            logger.warning(
                f"Collector timeout not enforced on {PLATFORM}. "
                "Set STRICT_TIMEOUT_ENFORCEMENT=true for subprocess isolation."
            )
            return collector.finalize(self)  # Run without timeout

    # Option A: Unix SIGALRM (already implemented)
    def timeout_handler(signum, frame):
        raise TimeoutError(f"Collector {collector.name} exceeded {timeout_seconds}s timeout")

    old_handler = signal.signal(signal.SIGALRM, timeout_handler)
    signal.alarm(timeout_seconds)

    try:
        result = collector.finalize(self)
        signal.alarm(0)  # Cancel alarm
        return result
    except TimeoutError as e:
        self._collector_errors.append({
            'collector': collector.name,
            'error': str(e),
            'type': 'timeout'
        })
        return []
    finally:
        signal.signal(signal.SIGALRM, old_handler)


def _run_collector_in_subprocess(self, collector, timeout_seconds):
    """
    Subprocess isolation for cross-platform timeout enforcement.

    YAGNI WARNING: Only implement if Windows deployment confirmed.
    Per CODE_QUALITY.json: Requires ticket ID + tech lead approval.
    """
    raise NotImplementedError(
        "Subprocess isolation not yet implemented. "
        "This requires YAGNI waiver (Windows deployment ticket). "
        "See CODE_QUALITY.json waiver_policy."
    )

    # TODO (when YAGNI Q1-Q3 pass):
    # 1. Serialize warehouse state
    # 2. Run collector in subprocess with timeout
    # 3. Deserialize results
    # See: tools/collector_worker.py (skeleton)

# EVIDENCE ANCHOR
# CLAIM-P0-4-EXPLICIT: Platform support explicitly documented and enforced
# Source: Executive summary B.1 + CODE_QUALITY.json PRIN-YAGNI
```

**Step 2: Document Platform Support Policy**

**Policy Reference**: See `policies/EXEC_PLATFORM_SUPPORT_POLICY.md` for complete policy

**Quick Summary**:
- **Supported Platforms (Full Enforcement)**: Linux & macOS (SIGALRM-based timeout)
- **Limited Support**: Windows (graceful degradation - warnings only, no enforcement)
- **Windows Deployment Options**:
  - **Option 1 (Default)**: Graceful degradation (`STRICT_TIMEOUT_ENFORCEMENT=false`)
  - **Option 2 (Strict)**: Subprocess isolation (requires YAGNI waiver, not implemented)
  - **Option 3 (Recommended)**: Linux-only deployment for production with untrusted inputs

**YAGNI Status**: Subprocess isolation NOT IMPLEMENTED (awaiting Windows deployment requirement)

**Testing**: `skeleton/tests/test_collector_timeout.py` (platform-aware tests)

**Step 3: Update Tests for Platform Awareness**

```python
# FILE: skeleton/tests/test_collector_timeout.py

import platform
import pytest

PLATFORM = platform.system()
SUPPORTS_TIMEOUT = (PLATFORM in ['Linux', 'Darwin'])

@pytest.mark.skipif(not SUPPORTS_TIMEOUT, reason="Timeout not supported on Windows (graceful degradation)")
def test_collector_timeout_enforced():
    """Verify timeout kills slow collector (Unix only)."""
    # ... existing test ...

@pytest.mark.skipif(SUPPORTS_TIMEOUT, reason="Test only for Windows graceful degradation")
def test_windows_timeout_warning():
    """Verify Windows logs warning instead of enforcing timeout."""
    import logging
    from doxstrux.markdown.utils.token_warehouse import TokenWarehouse

    # ... setup slow collector ...

    with pytest.warns(UserWarning, match="Collector timeout not enforced"):
        result = wh.dispatch_all()
```

**Step 4: Add Decision Point for Future Implementation**

```python
# FILE: tools/collector_worker.py (skeleton for future)

"""
Subprocess-based collector isolation for cross-platform timeout enforcement.

YAGNI STATUS: NOT IMPLEMENTED
BLOCKED BY: No Windows deployment requirement (CODE_QUALITY.json Q1 fails)

When to implement:
1. User confirms Windows production deployment (Q1: Real requirement âœ…)
2. User has immediate Windows deployment plan (Q2: Used immediately âœ…)
3. Concrete Windows user count/ticket (Q3: Backed by data âœ…)

Effort: 8 hours (design + implementation + testing)
"""

def run_collector_isolated(collector, warehouse_state, timeout_seconds):
    """
    Run collector in subprocess with timeout.

    THIS IS A PLACEHOLDER. Do not implement without YAGNI waiver.
    """
    raise NotImplementedError("Subprocess isolation pending YAGNI waiver")
```

**Success Criteria**:
- [ ] Platform support explicitly documented (policies/EXEC_PLATFORM_SUPPORT_POLICY.md)
- [ ] STRICT_TIMEOUT_ENFORCEMENT flag exists
- [ ] NotImplementedError raised if subprocess isolation attempted without waiver
- [ ] Tests skip Windows timeout enforcement (graceful)
- [ ] README.md updated with platform recommendations

**Time Estimate**: 2 hours (1h docs + 30min implementation + 30min tests)

**YAGNI GATE**: Subprocess isolation deferred until:
1. Windows deployment ticket created
2. Tech Lead approval obtained
3. User provides concrete deployment plan

---

# PART 2: P1 FIXES (1-2 Weeks)

## P1-1: Binary Search section_of()

### --- THINKING ---

**Problem Statement**:
- **CLAIM-P1-1-A**: section_of() uses linear scan
- **Evidence**: Executive summary Section C.2
- **Quote**: "If sections is a list of ranges, section_of() must be a binary search, not linear"
- **Impact**: O(N) lookups â†’ O(NÂ²) when called in hot loop
- **Severity**: ðŸŸ¡ MEDIUM - Performance degradation on large docs

**Current Status**:
- **CLAIM-P1-1-B**: Implementation varies by module
- **Evidence**: Code audit needed
- **Gap**: Some extractors may use linear scan

**YAGNI Assessment**:
- Q1: Real requirement? âœ… YES - Executive summary P1-1
- Q2: Used immediately? âœ… YES - Called frequently during extraction
- Q3: Backed by data? âœ… YES - O(N) vs O(log N) measurable
- Q4: Can defer? âœ… YES - Low-effort, high-gain fix
- **Outcome**: `implement_now = TRUE` (but lower priority than P0)

### --- EXECUTION ---

```python
# FILE: src/doxstrux/markdown/utils/section_utils.py

import bisect

def section_of(sections: list[dict], line_num: int) -> str | None:
    """
    Find section containing line_num using binary search.

    PERFORMANCE: O(log N) instead of O(N) linear scan.

    Args:
        sections: List of dicts with 'start_line' and 'id' keys (must be sorted)
        line_num: Line number to search for

    Returns:
        Section ID or None if not found
    """
    if not sections:
        return None

    # Binary search for rightmost section starting at or before line_num
    # bisect_right gives insertion point; we want section just before
    idx = bisect.bisect_right([s['start_line'] for s in sections], line_num)

    if idx == 0:
        return None  # Before first section

    return sections[idx - 1]['id']

# EVIDENCE ANCHOR
# CLAIM-P1-1-IMPL: Binary search reduces section lookup to O(log N)
# Source: Executive summary C.2
# Verification: Benchmark shows O(log N) growth
```

**Benchmark Test**:

```python
# FILE: skeleton/tests/test_section_lookup_performance.py

import time
from doxstrux.markdown.utils.section_utils import section_of

def test_section_of_is_logarithmic():
    """Verify section_of() scales as O(log N), not O(N)."""

    # Generate test sections
    def make_sections(n):
        return [{'id': f'sec_{i}', 'start_line': i * 10} for i in range(n)]

    sizes = [100, 1000, 10000]
    times = []

    for size in sizes:
        sections = make_sections(size)

        start = time.perf_counter()
        for _ in range(1000):
            section_of(sections, size * 5)  # Mid-point lookup
        elapsed = time.perf_counter() - start
        times.append(elapsed)

    # Check logarithmic growth
    # If O(log N): time[1] / time[0] â‰ˆ log(1000)/log(100) â‰ˆ 1.5
    # If O(N): time[1] / time[0] â‰ˆ 1000/100 = 10
    ratio = times[1] / times[0]

    assert ratio < 3.0, f"section_of() appears O(N), not O(log N): ratio={ratio}"
```

**Success Criteria**:
- [ ] Binary search implemented
- [ ] Benchmark shows <3x slowdown for 10x size increase
- [ ] All extractors use `section_of()` from `section_utils.py`

**Time Estimate**: 1 hour

---

## P1-2: Subprocess Isolation (Conditional - YAGNI Gated)

### --- THINKING ---

**YAGNI STOP CONDITION**:

Per CODE_QUALITY.json:
```json
"decision_tree": {
  "questions": [
    {"id": "q1", "question": "Is there a real, current requirement?"},
    {"id": "q2", "question": "Will it be used immediately?"},
    {"id": "q3", "question": "Is it backed by stakeholder request or concrete data?"}
  ],
  "outcome_logic": "implement_now = q1_yes && q2_yes && q3_yes && !q4_yes"
}
```

**Q1: Real requirement?**
- **Answer**: âš ï¸ **CONDITIONAL** - Only if Windows deployment confirmed
- **Evidence**: Executive summary Section B.1
- **Requirement**: User must provide Windows deployment ticket

**Q2: Used immediately?**
- **Answer**: âš ï¸ **UNKNOWN** - Depends on deployment timeline
- **Evidence**: No Windows deployment timeline in current docs

**Q3: Backed by stakeholder/data?**
- **Answer**: âŒ **NO** - No Windows user count, no production deployment plan
- **Evidence**: No stakeholder request documented

**OUTCOME**: `STOP_CLARIFICATION_REQUIRED`

### --- STOP BLOCK ---

**Type**: STOP_CLARIFICATION_REQUIRED
**Reason**: Subprocess isolation violates YAGNI without Windows deployment confirmation
**Blocking**: CODE_QUALITY.json Q1-Q3 not satisfied
**Needed**:
1. Windows deployment ticket ID
2. Concrete Windows deployment timeline
3. Estimated Windows user count OR stakeholder approval

**Next Step After Unblock**:
1. Create ticket: "Windows Production Deployment - Subprocess Isolation Required"
2. Get Tech Lead approval (waiver_policy)
3. Implement `tools/collector_worker.py` (8h effort)
4. Add tests: `test_subprocess_isolation_windows.py`

**Interim Solution**: Document Linux-only policy (P0-4 already covers this)

---

# PART 3: P2 FIXES (2-4 Weeks)

## P2-1: PR Checklist Automation

### --- THINKING ---

**Problem Statement**:
- **CLAIM-P2-1-A**: PR checklist currently manual
- **Evidence**: Executive summary Section D.4
- **Quote**: "Automate policy validation as part of pre-commit or CI... lint for blocking imports (requests in collectors)"
- **Impact**: Human error allows YAGNI violations to merge
- **Severity**: ðŸŸ¢ LOW - Process improvement (not security)

**YAGNI Assessment**:
- Q1: Real requirement? âœ… YES - Executive summary P2-1
- Q2: Used immediately? âœ… YES - Every PR
- Q3: Backed by data? âœ… YES - CODE_QUALITY.json defines checklist
- Q4: Can defer? âœ… YES - Manual checklist works but error-prone
- **Outcome**: `implement_later = TRUE` (P2 priority)

### --- EXECUTION ---

**Step 1: Create Pre-Commit Hook**

```python
# FILE: .pre-commit-config.yaml

repos:
  - repo: local
    hooks:
      - id: yagni-checker
        name: YAGNI Compliance Check
        entry: python scripts/check_yagni.py
        language: system
        pass_filenames: false

      - id: blocking-io-lint
        name: Collector Blocking I/O Check
        entry: python tools/lint_collectors.py
        language: system
        files: 'src/doxstrux/markdown/collectors.*\.py$'

      - id: pr-checklist-validator
        name: PR Checklist Validation
        entry: python scripts/validate_pr_checklist.py
        language: system
        pass_filenames: false
```

**Step 2: Implement YAGNI Checker**

```python
# FILE: scripts/check_yagni.py

"""
YAGNI compliance checker.

Per CODE_QUALITY.json: Detects speculative code patterns.
"""

import ast
import sys
from pathlib import Path

YAGNI_VIOLATIONS = [
    # Pattern: Unused parameters
    ('unused_param', 'Parameter never used in function body'),

    # Pattern: Speculative flags
    ('speculative_flag', 'Boolean flag with only one code path'),

    # Pattern: Unused extension points
    ('unused_hook', 'Hook parameter never called'),
]

def check_file(filepath):
    """Check Python file for YAGNI violations."""
    with open(filepath) as f:
        tree = ast.parse(f.read(), filename=str(filepath))

    violations = []

    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            # Check for unused parameters
            param_names = {arg.arg for arg in node.args.args}
            used_names = {n.id for n in ast.walk(node) if isinstance(n, ast.Name)}
            unused = param_names - used_names

            for param in unused:
                violations.append({
                    'file': filepath,
                    'line': node.lineno,
                    'type': 'unused_param',
                    'message': f'Parameter "{param}" never used (YAGNI violation)',
                    'severity': 'warning'
                })

    return violations

if __name__ == '__main__':
    src_files = Path('src').rglob('*.py')
    all_violations = []

    for filepath in src_files:
        all_violations.extend(check_file(filepath))

    if all_violations:
        print(f"âŒ YAGNI violations detected: {len(all_violations)}")
        for v in all_violations:
            print(f"  {v['file']}:{v['line']} - {v['message']}")
        sys.exit(1)
    else:
        print("âœ… YAGNI compliance check passed")
        sys.exit(0)
```

**Step 3: Add CI Gate**

```yaml
# FILE: .github/workflows/code-quality-gate.yml

name: Code Quality Gate

on: [pull_request]

jobs:
  yagni-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
      - run: python scripts/check_yagni.py

  blocking-io-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
      - run: python tools/lint_collectors.py src/doxstrux/markdown/collectors/
```

**Success Criteria**:
- [ ] Pre-commit hooks installed
- [ ] YAGNI checker detects unused params
- [ ] Blocking I/O linter runs on every PR
- [ ] CI gate fails on violations

**Time Estimate**: 4 hours

---

## P2-2: KISS Routing Table Refactor

### --- THINKING ---

**Problem Statement**:
- **CLAIM-P2-2-A**: Routing table bitmask logic is complex
- **Evidence**: Executive summary Section D.2
- **Quote**: "Routing table code is clever (bitmasking, etc.), but readability suffers. KISS: wrap bitmask complexity behind well-documented helpers"
- **Impact**: Hard to maintain, violates KISS principle
- **Severity**: ðŸŸ¢ LOW - Maintainability (not correctness)

**KISS Refactor Plan**:
1. Extract bitmask logic into `routing_utils.py`
2. Add property-based tests for determinism
3. Document bitmask algebra

### --- EXECUTION ---

```python
# FILE: src/doxstrux/markdown/utils/routing_utils.py

"""
Routing table utilities - KISS-compliant bitmask helpers.

Per CODE_QUALITY.json PRIN-KISS: "wrap bitmask complexity behind
well-documented helpers"
"""

from typing import Set

class RoutingTable:
    """
    Manages collector routing bitmasks.

    KISS Principle: Hides bitmasking complexity behind clear API.
    """

    def __init__(self):
        self._mask_map: dict[str, int] = {}
        self._collector_masks: dict = {}

    def register_ignore_set(self, collector, ignore_types: Set[str]) -> int:
        """
        Register collector's ignore set and return bitmask.

        DETERMINISTIC: Sorts ignore_types to ensure consistent ordering.

        Args:
            collector: Collector instance
            ignore_types: Set of token types to ignore

        Returns:
            Bitmask for this collector's ignore set
        """
        mask = 0

        # âœ… CRITICAL: Sort for determinism (per Executive summary C.4)
        for token_type in sorted(ignore_types):
            if token_type not in self._mask_map:
                self._mask_map[token_type] = len(self._mask_map)

            bit_position = self._mask_map[token_type]
            mask |= (1 << bit_position)

        self._collector_masks[collector] = mask
        return mask

    def should_ignore(self, collector, token_type: str, active_mask: int) -> bool:
        """
        Check if collector should ignore token based on active mask.

        Args:
            collector: Collector instance
            token_type: Type of current token
            active_mask: Bitmask of active ignore contexts

        Returns:
            True if collector should skip this token
        """
        collector_mask = self._collector_masks.get(collector, 0)

        # If collector's ignore set overlaps with active mask, skip
        return bool(collector_mask & active_mask)

# EVIDENCE ANCHOR
# CLAIM-P2-2-KISS: Routing logic encapsulated in clear API
# Source: Executive summary D.2 + CODE_QUALITY.json PRIN-KISS
```

**Property-Based Test**:

```python
# FILE: skeleton/tests/test_routing_determinism.py

import random
from doxstrux.markdown.utils.routing_utils import RoutingTable

def test_routing_determinism_property():
    """
    Property test: Routing table is deterministic regardless of
    collector registration order.

    Per Executive summary: "property-based tests that assert
    deterministic order regardless of dict iteration order"
    """
    # Create two routing tables
    table1 = RoutingTable()
    table2 = RoutingTable()

    # Same collectors, different registration order
    collectors = [
        ('links', {'blockquote', 'code_fence'}),
        ('headings', {'code_inline'}),
        ('images', {'blockquote'}),
    ]

    # Shuffle for table1
    random.shuffle(collectors)
    for name, ignore_set in collectors:
        table1.register_ignore_set(name, ignore_set)

    # Different shuffle for table2
    random.shuffle(collectors)
    for name, ignore_set in collectors:
        table2.register_ignore_set(name, ignore_set)

    # ASSERTION: Bitmasks must be identical
    assert table1._collector_masks == table2._collector_masks, \
        "Routing table non-deterministic (violates Executive summary C.4)"
```

**Success Criteria**:
- [ ] Bitmask logic extracted to `routing_utils.py`
- [ ] Property test passes (determinism)
- [ ] Code review confirms improved readability

**Time Estimate**: 3 hours

---

# PART 4: Testing & Monitoring (Per Executive Summary Section F)

## Required Tests Before Canary

### PR Fast Gate (< 2 minutes)

```yaml
# FILE: .github/workflows/pr-fast-gate.yml

name: PR Fast Gate

on: [pull_request, push]

jobs:
  security-fast-gate:
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -e .
          pip install -e ".[dev]"

      # P0-1: URL Normalization Parity
      - name: URL Normalization Parity Test
        run: |
          pytest skeleton/tests/test_url_normalization_parity.py::test_collector_fetcher_normalization_parity -v
        continue-on-error: false

      # P0-2: HTML/XSS Litmus
      - name: HTML/XSS Litmus Tests
        run: |
          pytest skeleton/tests/test_html_render_litmus.py -v
        continue-on-error: false

      # P0-3: Collector Caps
      - name: Collector Caps Tests
        run: |
          pytest skeleton/tests/test_collector_caps_end_to_end.py::test_links_collector_enforces_cap -v
          pytest skeleton/tests/test_collector_caps_end_to_end.py::test_images_collector_enforces_cap -v
        continue-on-error: false

      # Combined Adversarial
      - name: Adversarial Combined Smoke Test
        run: |
          pytest skeleton/tests/test_template_injection_end_to_end.py -v
          pytest skeleton/tests/test_html_xss_end_to_end.py -v
        continue-on-error: false
```

### Nightly Full Suite

```yaml
# FILE: .github/workflows/nightly-full-suite.yml

name: Nightly Full Adversarial Suite

on:
  schedule:
    - cron: '0 2 * * *'  # 2 AM UTC
  workflow_dispatch:

jobs:
  full-adversarial:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4

      - name: Run All 9 Adversarial Corpora
        run: |
          for corpus in adversarial_corpora/adversarial_*.json; do
            pytest skeleton/tests/ --corpus="$corpus" -v
          done

      - name: Store Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: adversarial-results
          path: test-results/
```

### Metrics & Alerts (Prometheus/Grafana)

```yaml
# FILE: monitoring/prometheus_rules.yml

groups:
  - name: doxstrux_security
    interval: 30s
    rules:
      # P0 Alerts (per Executive summary Section F)

      - alert: ParseTimeP99High
        expr: histogram_quantile(0.99, parse_duration_seconds_bucket) > (baseline_parse_p99 * 2)
        for: 2m
        labels:
          severity: P0
        annotations:
          summary: "Parse time p99 > 2x baseline for 2 minutes"
          description: "Current: {{ $value }}s, Baseline: {{ baseline_parse_p99 }}s"

      - alert: CollectorTimeoutSpike
        expr: rate(collector_timeout_total[1m]) > 0.01
        for: 1m
        labels:
          severity: P0
        annotations:
          summary: "Collector timeout rate > 1% for 1 minute"

      - alert: MemoryP99High
        expr: histogram_quantile(0.99, parse_peak_rss_mb_bucket) > 500
        for: 2m
        labels:
          severity: P0
        annotations:
          summary: "Memory p99 > 500MB for 2 minutes"

      - alert: CollectorErrorsNonZero
        expr: collector_errors_total > 0
        for: 5m
        labels:
          severity: P1
        annotations:
          summary: "Collector errors detected"
```

---

# PART 5: Green-Light Checklist (Per Executive Summary Section G)

## Pre-Merge PR Review Checklist

```markdown
# PR Review Checklist - Green-Light Gate

**PR #**: ___________
**Author**: ___________
**Reviewer**: ___________
**Date**: ___________

## P0 Security Fixes (All MUST Pass)

- [ ] **P0-1: URL Normalization Parity**
  - [ ] `test_collector_fetcher_normalization_parity` passes
  - [ ] `grep -r "def normalize_url"` returns exactly 1 result
  - [ ] All collectors import from `url_utils.py`

- [ ] **P0-2: HTML/XSS Litmus**
  - [ ] `test_html_render_litmus.py` all tests pass
  - [ ] `policies/EXEC_ALLOW_RAW_HTML_POLICY.md` exists and reviewed
  - [ ] HTMLCollector.allow_html defaults to False

- [ ] **P0-3: Per-Collector Caps**
  - [ ] `test_collector_caps_end_to_end.py` all tests pass
  - [ ] Truncation metadata returned in finalize()
  - [ ] Metrics logged for monitoring

- [ ] **P0-4: Cross-Platform Isolation**
  - [ ] `policies/EXEC_PLATFORM_SUPPORT_POLICY.md` exists
  - [ ] STRICT_TIMEOUT_ENFORCEMENT flag implemented
  - [ ] Tests skip Windows timeout enforcement

## CODE_QUALITY Compliance (Per CODE_QUALITY.json)

- [ ] **PR_CHECK_REQ_ID**: Current requirement ID referenced
- [ ] **PR_CHECK_IMMEDIATE_USE**: Feature used immediately
- [ ] **PR_CHECK_NO_SPECULATIVE**: No speculative flags/hooks
- [ ] **PR_CHECK_TESTS**: Tests prove necessity (fail-before, pass-after)
- [ ] **PR_CHECK_KISS**: Simpler alternative considered and documented

## YAGNI Evidence (If New Features Added)

- [ ] Q1: Real requirement exists? (Ticket ID: _______)
- [ ] Q2: Used immediately? (Consumer: _______)
- [ ] Q3: Backed by stakeholder/data? (Evidence: _______)
- [ ] Q4: Cannot defer? (Justification: _______)

## CI/CD Gates (All MUST Pass)

- [ ] PR fast gate passes (adversarial smoke)
- [ ] URL normalization parity tests pass
- [ ] HTML litmus tests pass
- [ ] Collector caps tests pass
- [ ] Static security analysis passes (Bandit + blocking I/O)

## Evidence Anchors (Per Golden CoT)

- [ ] All claims have evidence sources
- [ ] All quotes have line numbers
- [ ] All decisions have impact statements
- [ ] All risks have mitigations

## Sign-Off

- [ ] **Security Lead**: ___________
- [ ] **Engineering Lead**: ___________
- [ ] **Tech Lead** (if waiver): ___________

**Approval Date**: ___________
**Merge Date**: ___________
```

---

# PART 6: Rollback Plan (Failure Paths)

## If P0-1 (URL Normalization) Fails

**Trigger**: Test `test_collector_fetcher_normalization_parity` fails

**Rollback**:
```bash
# 1. Identify divergence
pytest skeleton/tests/test_url_normalization_parity.py -v --tb=long

# 2. Compare implementations
diff <(grep -A 20 "def normalize_url" src/doxstrux/markdown/utils/url_utils.py) \
     <(grep -A 20 "def normalize_url" <fetcher_code>.py)

# 3. Fix discrepancy in one location (enforce single source of truth)

# 4. Re-run tests
pytest skeleton/tests/test_url_normalization_parity.py -v

# 5. If still failing, do NOT merge PR
```

## If P0-2 (HTML Litmus) Fails

**Trigger**: Script tags or event handlers detected in rendered output

**Rollback**:
```bash
# 1. Disable HTMLCollector in production
# Set environment variable
export DISABLE_HTML_COLLECTOR=true

# 2. Investigate sanitization failure
pytest skeleton/tests/test_html_render_litmus.py -v --tb=long

# 3. Check Bleach version
pip show bleach

# 4. Update Bleach if vulnerable
pip install --upgrade bleach

# 5. Re-run litmus tests
pytest skeleton/tests/test_html_render_litmus.py -v
```

## If P0-3 (Collector Caps) Fails

**Trigger**: OOM kill in production OR test shows unbounded growth

**Rollback**:
```bash
# 1. Check current cap enforcement
grep "MAX_.*_PER_DOC" src/doxstrux/markdown/config.py

# 2. Verify collectors use caps
grep -r "MAX_LINKS_PER_DOC" src/doxstrux/markdown/extractors/

# 3. If missing, add emergency cap in warehouse
# FILE: src/doxstrux/markdown_parser_core.py
# Add global limit:
MAX_TOTAL_ITEMS = 100_000

# 4. Monitor memory usage
# Check Prometheus: parse_peak_rss_mb

# 5. Lower caps if needed
# Edit config.py, redeploy
```

---

# PART 7: Timeline & Effort Summary

## P0 Critical (24-48 Hours)

| Task | Effort | Timeline | Owner | Blocker |
|------|--------|----------|-------|---------|
| P0-1: URL Normalization | 3h | Day 1 AM | Security Team | None |
| P0-2: HTML Litmus | 4h | Day 1 PM | Security Team | None |
| P0-3: Collector Caps | 2h | Day 1 PM | Platform Team | None |
| P0-4: Platform Policy | 2h | Day 2 AM | DevOps Team | None |

**Total P0**: 11 hours (1.5 days)

## P1 High Priority (1-2 Weeks)

| Task | Effort | Timeline | Owner | Blocker |
|------|--------|----------|-------|---------|
| P1-1: Binary Search | 1h | Week 1 | Performance Team | None |
| P1-2: Proc Isolation | 8h | Week 2 | Platform Team | **YAGNI GATE** |

**Total P1**: 9 hours (conditional on P1-2)

## P2 Medium Priority (2-4 Weeks)

| Task | Effort | Timeline | Owner | Blocker |
|------|--------|----------|-------|---------|
| P2-1: PR Automation | 4h | Week 3 | DevOps Team | None |
| P2-2: KISS Refactor | 3h | Week 3 | Platform Team | None |

**Total P2**: 7 hours

## Grand Total

- **Minimum** (P0 only): 11 hours
- **Recommended** (P0 + P1-1): 12 hours
- **Full** (P0 + P1 + P2, if YAGNI passes): 27 hours

---

# PART 8: Success Metrics (30-Day Post-Green-Light)

## Correctness (Per GREEN_LIGHT_ROLLOUT_CHECKLIST.md)

- [ ] Baseline parity maintained (542/542 tests passing)
- [ ] Zero user-reported regressions
- [ ] Zero security incidents

## Performance

- [ ] p99 parse time within 10% of baseline
- [ ] p99 memory usage within 20% of baseline
- [ ] Zero OOM kills

## Reliability

- [ ] 99.9% uptime (excluding planned maintenance)
- [ ] < 0.01% collector timeout rate
- [ ] Zero P0 alerts

## Security

- [ ] All adversarial corpora passing (9/9)
- [ ] Zero XSS/SSTI/RCE vulnerabilities
- [ ] External security audit: no P0/P1 findings

---

# PART 9: Evidence Summary (Golden CoT Validation)

## Claims â†’ Evidence Mapping

| Claim ID | Statement | Evidence Source | Verification |
|----------|-----------|-----------------|--------------|
| CLAIM-001 | Test infrastructure 100% complete | SECURITY_IMPLEMENTATION_STATUS.md:16-23 | âœ… 62 tests exist |
| CLAIM-002 | 4 P0 gaps remain | Executive summary | âœ… User feedback |
| CLAIM-P0-1-A | URL normalization mismatch risk | Executive summary A.1 | âœ… TOCTOU attack vector |
| CLAIM-P0-1-B | Tests exist but incomplete | SECURITY_IMPLEMENTATION_STATUS.md:51-78 | âœ… Parity verification pending |
| CLAIM-P0-2-A | HTML sanitization blindspots | Executive summary A.2 | âœ… SVG XSS vectors |
| CLAIM-P0-3-A | Unbounded collection â†’ OOM | Executive summary B.2 | âœ… adversarial_large.json |
| CLAIM-P0-4-A | SIGALRM Unix-only | Executive summary B.1 | âœ… Windows DoS risk |

## Risk â†’ Mitigation Traceability

| Risk ID | Description | Likelihood | Impact | Mitigation | Status |
|---------|-------------|------------|--------|------------|--------|
| RISK-P0-1 | SSRF via URL bypass | HIGH | HIGH | Centralized normalize_url() | â³ In Progress |
| RISK-P0-2 | XSS via HTML/SVG | MEDIUM | HIGH | Default-off + Bleach sanitization | â³ In Progress |
| RISK-P0-3 | OOM via unbounded collection | MEDIUM | HIGH | Per-collector caps | â³ In Progress |
| RISK-P0-4 | DoS on Windows (no timeout) | LOW | MEDIUM | Platform support policy | â³ In Progress |
| RISK-P1-2 | Windows timeout bypass | LOW | MEDIUM | **YAGNI DEFERRED** | ðŸ”´ Blocked |

---

# PART 10: Final Recommendations

## Immediate Actions (Next 48 Hours)

1. **Start with P0-1** (URL Normalization) - Highest SSRF risk
2. **Then P0-3** (Collector Caps) - Quick win (2h), high impact
3. **Then P0-2** (HTML Litmus) - Requires most testing
4. **Finally P0-4** (Platform Policy) - Documentation-heavy

## YAGNI Decision Required

**QUESTION FOR USER** (STOP_CLARIFICATION_REQUIRED):

> Do you have a **concrete Windows production deployment plan** for Phase 8?
>
> - [ ] **YES** â†’ Implement subprocess isolation (P1-2, 8h effort)
> - [ ] **NO** â†’ Document "Linux-only for untrusted inputs" (P0-4, already done)
>
> **Evidence Needed** (per CODE_QUALITY.json):
> - Ticket ID for Windows deployment
> - Estimated Windows user count
> - Deployment timeline

**If NO**: Close P1-2 as "Won't Implement (YAGNI)"
**If YES**: Require Tech Lead waiver approval before starting

## Code Quality Enforcement

**Automate These Checks** (P2-1):
1. Pre-commit: YAGNI checker, blocking I/O linter
2. PR gate: All P0 tests as hard fails
3. Nightly: Full adversarial suite + memory profiling

## Monitoring Strategy

**Week 1 Post-Green-Light**:
- Watch p99 parse time (alert if >2x baseline)
- Watch collector timeout rate (alert if >1%)
- Watch memory p99 (alert if >500MB)

**Month 1 Post-Green-Light**:
- Run external security audit
- Review all P0/P1 alerts
- Update adversarial corpora with new patterns

---

**END OF CLOSING_IMPLEMENTATION.md**

**Version**: 1.0
**Last Updated**: 2025-10-16
**Status**: READY FOR EXECUTION
**Next Review**: After P0 completion (48h)
**Owner**: Security + Platform Teams

---

## Quick Start Commands

```bash
# Step 1: Run current test suite
pytest skeleton/tests/test_*_end_to_end.py -v

# Step 2: Implement P0-1 (URL normalization)
# (See PART 1, P0-1 section above)

# Step 3: Implement P0-3 (collector caps)
# (See PART 1, P0-3 section above)

# Step 4: Implement P0-2 (HTML litmus)
# (See PART 1, P0-2 section above)

# Step 5: Document P0-4 (platform policy)
# (See PART 1, P0-4 section above)

# Step 6: Run full security suite
pytest skeleton/tests/ -v --tb=short

# Step 7: Request green-light approval
# (Use GREEN_LIGHT_ROLLOUT_CHECKLIST.md)
```

---

# APPENDIX: Ready-to-Use Patches

**Purpose**: Copy-paste implementation code for immediate execution

**Source**: User-provided patches (verified against executive summary requirements)

---

## Patch A: Binary Search Helper (P1-1)

**File**: `doxstrux/markdown/utils/token_warehouse.py`

**Location**: Add near top of module (after imports)

```python
# --- Patch A: Binary search helper for section lookups ---
import bisect
from typing import List, Optional, Tuple

def section_index_for_line(sections: List[Tuple[int,int]], lineno: int) -> Optional[int]:
    """
    Given sections = [(start0,end0), (start1,end1), ...] sorted by start,
    return the index i such that start_i <= lineno <= end_i, or None if not found.

    PERFORMANCE: O(log N) instead of O(N) linear scan (per Executive summary C.2).

    This helper is intentionally small and deterministic; it can be embedded into
    TokenWarehouse.section_of() or used by collectors who need fast O(log n) lookups.

    Args:
        sections: List of (start, end) tuples sorted by start line
        lineno: Line number to search for

    Returns:
        Section index or None if not found

    Example:
        >>> sections = [(0, 4), (5, 9), (10, 14)]
        >>> section_index_for_line(sections, 7)
        1  # Second section (5-9) contains line 7
    """
    if not sections:
        return None

    # Build starts list (first element of each tuple)
    starts = [s for (s, e) in sections]
    i = bisect.bisect_right(starts, lineno) - 1

    if i < 0:
        return None

    s, e = sections[i]
    if s <= lineno <= e:
        return i

    return None


def section_of(self, lineno: int) -> Optional[int]:
    """
    Find section index for given line number using binary search helper.

    Expects self.sections to be a list of (start, end) tuples sorted by start.

    PERFORMANCE: O(log N) via binary search (replaces O(N) linear scan).
    """
    return section_index_for_line(self.sections, lineno)
```

**Integration Notes**:
- If your `self.sections` tuples have a different shape (e.g., `(id, start, end, ...)`), adapt the helper to extract start/end fields
- Replace existing linear `section_of()` implementation with the call to `section_index_for_line()`

---

## Patch B: Per-Collector Caps (P0-3)

**File**: `doxstrux/markdown/collectors_phase8/links.py`

**Action**: Replace or create LinksCollector with cap enforcement

```python
# --- Patch B: LinksCollector with per-document cap ---
from typing import List, Dict, Any, Optional

# Tunable cap per Executive summary P0-3
MAX_LINKS_PER_DOC = 10_000

class LinksCollector:
    """
    Links collector with hard cap to prevent OOM (per Executive summary B.2).

    Enforces MAX_LINKS_PER_DOC limit and records truncation metadata.
    """
    name = "links"

    def __init__(self, max_links: Optional[int] = None):
        self.max_links = max_links if max_links is not None else MAX_LINKS_PER_DOC
        self._links: List[Dict[str, Any]] = []
        self._truncated: bool = False

    @property
    def interest(self):
        # Simple interest declaration for registration
        class I:
            types = {"link_open", "link_close", "link"}
            tags = set()
            ignore_inside = set()
            predicate = None
        return I()

    def should_process(self, token_view: Dict[str, Any], ctx, wh) -> bool:
        # Decide based on view; default True for links
        return token_view.get("type", "") in ("link_open", "link")

    def on_token(self, idx: int, token_view: Dict[str, Any], ctx, wh) -> None:
        """
        Process link token with cap enforcement.

        CRITICAL: Checks cap BEFORE appending to prevent unbounded growth.
        """
        # token_view is expected to be the canonical primitive dict
        ttype = token_view.get("type")
        if ttype not in ("link_open", "link"):
            return

        # âœ… CRITICAL: Enforce cap BEFORE appending
        if len(self._links) >= self.max_links:
            # Set truncated flag, do not append further links
            self._truncated = True
            return

        href = token_view.get("href") or token_view.get("info") or token_view.get("content")
        self._links.append({
            "token_index": idx,
            "href": href,
            "text": token_view.get("content", "") or "",
        })

    def finalize(self, wh) -> Dict[str, Any]:
        """
        Return collected links with truncation metadata.

        CRITICAL: Truncation metadata signals when cap was hit (per Executive summary P0-3).
        """
        return {
            "name": self.name,
            "count": len(self._links),
            "truncated": self._truncated,
            "links": list(self._links),
        }
```

**Repeat Pattern For**:
- `media.py` (MAX_IMAGES_PER_DOC = 5_000)
- `sections.py` (MAX_HEADINGS_PER_DOC = 5_000)
- `codeblocks.py` (MAX_CODE_BLOCKS_PER_DOC = 2_000)
- `tables.py` (MAX_TABLES_PER_DOC = 1_000)
- `lists.py` (MAX_LIST_ITEMS_PER_DOC = 50_000)

**Notes**:
- This approach avoids uncontrolled growth (per Executive summary B.2)
- If you keep aggregated data elsewhere, apply the same cap where lists are stored
- Make `MAX_*_PER_DOC` configurable via environment/config if needed

---

## Test 1: URL Normalization Parity (P0-1)

**File**: `tests/test_url_normalization_parity.py`

```python
# tests/test_url_normalization_parity.py
"""
URL Normalization Parity Test (P0-1)

Verifies collector â†” fetcher use identical normalization (per Executive summary A.1).

CRITICAL: This test validates the TOCTOU security property.
"""
import importlib
import json
from pathlib import Path
import pytest

ADVERSARIAL_FILE = Path("adversarial_corpora/adversarial_encoded_urls.json")

def try_import_candidates(module_names):
    """Try multiple module names to find normalizer."""
    for name in module_names:
        try:
            m = importlib.import_module(name)
            return m
        except Exception:
            continue
    return None

def normalize_or_none(module, func_names, value):
    """Try multiple function names to call normalizer."""
    for fname in func_names:
        fn = getattr(module, fname, None)
        if fn is None:
            continue
        try:
            return fn(value)
        except Exception:
            return None
    return None

def test_url_normalization_parity():
    """
    Verify collector and fetcher normalize URLs identically.

    Per Executive summary A.1: "Centralized one normalize_and_validate_url()
    in security/validators.py and import it from both collector and fetcher."
    """
    if not ADVERSARIAL_FILE.exists():
        pytest.skip(f"{ADVERSARIAL_FILE} not present; skip parity test")

    # Canonical normalizer (collector-side)
    security_mod = try_import_candidates([
        "security.validators",
        "security.validate",
        "security.validators_url",
        "doxstrux.markdown.security.validators"
    ])
    if not security_mod:
        pytest.skip("security.validators module not found; skip parity test")

    # Try to find a fetcher normalization implementation to compare against
    fetcher_mod = try_import_candidates([
        "doxstrux.markdown.fetchers.preview",
        "doxstrux.markdown.utils.normalize_url",
        "doxstrux.markdown.utils.urlutils",
        "doxstrux.markdown.security.url"
    ])

    if not fetcher_mod:
        pytest.skip("No fetcher-side normalization module found; "
                    "please add fetcher normalizer for parity test")

    # Load adversarial URLs
    objs = json.loads(ADVERSARIAL_FILE.read_text(encoding="utf-8"))

    # Adversarial file may be list of token objects or list of url strings; extract heuristically
    urls = []
    for o in objs:
        if isinstance(o, str):
            urls.append(o)
        elif isinstance(o, dict):
            # Try common fields
            for k in ("href", "url", "content"):
                v = o.get(k)
                if isinstance(v, str):
                    urls.append(v)
                    break
        else:
            continue

    assert urls, "No urls found in adversarial file; adapt file format"

    # Functions to try on each module
    sec_funcs = ["normalize_url", "normalize", "validate_url"]
    fetch_funcs = ["normalize_url", "normalize", "normalize_href"]

    mismatches = []
    for u in urls:
        sec_norm = normalize_or_none(security_mod, sec_funcs, u)
        fetch_norm = normalize_or_none(fetcher_mod, fetch_funcs, u)

        # If either side returned None (invalid), treat None as normalized invalid result
        if sec_norm != fetch_norm:
            mismatches.append((u, sec_norm, fetch_norm))

    assert not mismatches, (
        f"âŒ CRITICAL: Normalization mismatch detected between collector and fetcher "
        f"for {len(mismatches)} urls (TOCTOU vulnerability): {mismatches[:5]}"
    )
```

**Notes**:
- Test is forgiving about module/function names; adapt candidate lists to match your code
- If fetcher normalizer is not present, test will skip
- CI should ensure both sides exist before gating

---

## Test 2: HTML XSS Litmus (P0-2)

**File**: `tests/test_html_xss_litmus.py`

```python
# tests/test_html_xss_litmus.py
"""
HTML/XSS Litmus Test (P0-2)

End-to-end test: Parse â†’ Store â†’ Render (per Executive summary A.2).
"""
import importlib
import json
from pathlib import Path
import pytest

ADVERSARIAL_HTML = Path("adversarial_corpora/adversarial_html_xss.json")

def make_token(obj):
    """Create mock token from dict."""
    class Tok:
        def __init__(self, o):
            self.type = o.get("type")
            self.nesting = o.get("nesting", 0)
            self.tag = o.get("tag")
            self.map = o.get("map")
            self.content = o.get("content", "")
            self.href = o.get("href")
        def attrGet(self, name):
            return getattr(self, name, None)
    return Tok(obj)

def test_html_collector_flags_and_sanitizes():
    """
    Verify HTMLCollector flags HTML with needs_sanitization and sanitizes dangerous content.

    Per Executive summary A.2: "Litmus test: parse â†’ persist â†’ server-side render into
    a real template in a sandboxed environment, assert no executable scripts or on* attributes remain."
    """
    if not ADVERSARIAL_HTML.exists():
        pytest.skip(f"{ADVERSARIAL_HTML} missing")

    try:
        html_mod = importlib.import_module("doxstrux.markdown.collectors_phase8.html_collector")
    except Exception:
        pytest.skip("HtmlCollector module not found")

    HTMLCollector = getattr(html_mod, "HTMLCollector", None)
    if HTMLCollector is None:
        pytest.skip("HTMLCollector class not present")

    data = json.loads(ADVERSARIAL_HTML.read_text(encoding="utf-8"))
    tokens = [make_token(tk) for tk in data]

    # --- Test 1: Default-off behavior (fail-closed) ---
    c_default = HTMLCollector(allow_html=False)
    for i, tok in enumerate(tokens):
        tv = {
            "type": getattr(tok, "type", None),
            "content": getattr(tok, "content", None),
            "href": getattr(tok, "href", None)
        }
        c_default.on_token(i, tv, None, None)

    out_default = c_default.finalize(None)

    # When allow_html=False, collector should produce empty list
    assert not out_default, (
        "âŒ CRITICAL: HTMLCollector with allow_html=False should not return HTML content "
        "(fail-closed policy violated)"
    )

    # --- Test 2: Sanitization when enabled ---
    try:
        import bleach  # type: ignore
        bleach_ok = True
    except Exception:
        bleach_ok = False

    c = HTMLCollector(allow_html=True, sanitize_on_finalize=bleach_ok)
    for i, tok in enumerate(tokens):
        tv = {
            "type": getattr(tok, "type", None),
            "content": getattr(tok, "content", None),
            "href": getattr(tok, "href", None)
        }
        c.on_token(i, tv, None, None)

    result = c.finalize(None)

    # When allow_html=True, result should include items or sanitized outputs
    assert result, "HTMLCollector(allow_html=True) should return collected html blocks"

    # If sanitization enabled, ensure obvious vectors removed
    if bleach_ok:
        cleaned_concat = "\n".join([r.get("content","") for r in result])
        lower = cleaned_concat.lower()

        # âœ… CRITICAL ASSERTIONS (per Executive summary A.2)
        assert "<script" not in lower, "âŒ <script> tags not stripped by sanitizer"
        assert "onerror" not in lower and "onload" not in lower, (
            "âŒ Event handlers (onerror/onload) not stripped by sanitizer"
        )
```

**Notes**:
- If `bleach` not installed, test still checks collection behavior without asserting sanitization
- Installing `bleach` in CI makes test stricter
- Adapt to your template rendering system if using Jinja2/Django/etc.

---

## Test 3: Collector Caps (P0-3)

**File**: `tests/test_collector_caps.py`

```python
# tests/test_collector_caps.py
"""
Collector Caps Test (P0-3)

Verifies per-collector caps prevent OOM (per Executive summary B.2).
"""
import importlib
from pathlib import Path
import pytest

def make_link_token(idx):
    """Create mock link token."""
    class Tok:
        def __init__(self, idn):
            self.type = "link_open"
            self.nesting = 1
            self.tag = "a"
            self.map = [idn, idn]
            self.content = f"text-{idn}"
            self.href = f"https://example.com/{idn}"
        def attrGet(self, name):
            if name == "href":
                return self.href
            return None
    return Tok(idx)

def test_links_collector_truncation():
    """
    Verify LinksCollector enforces MAX_LINKS_PER_DOC cap and sets truncated flag.

    Per Executive summary B.2: "Enforce per-collector caps + truncation metadata,
    and add adversarial_large.json run in PR smoke or nightly."
    """
    try:
        links_mod = importlib.import_module("doxstrux.markdown.collectors_phase8.links")
        wh_mod = importlib.import_module("doxstrux.markdown.utils.token_warehouse")
    except Exception:
        pytest.skip("links collector or TokenWarehouse not importable")

    LinksCollector = getattr(links_mod, "LinksCollector", None)
    TokenWarehouse = getattr(wh_mod, "TokenWarehouse", None)
    if LinksCollector is None or TokenWarehouse is None:
        pytest.skip("required classes not present")

    # Craft many tokens to exceed MAX_LINKS_PER_DOC
    # Use twice the cap to be safe
    cap = getattr(links_mod, "MAX_LINKS_PER_DOC", 1000)
    n = cap * 2
    tokens = [make_link_token(i) for i in range(n)]

    wh = TokenWarehouse(tokens, tree=None)
    coll = LinksCollector()

    try:
        wh.register_collector(coll)
    except Exception:
        # Defensive: if register_collector not available, try direct append
        try:
            wh._collectors.append(coll)
        except Exception:
            pytest.skip("cannot register collector")

    wh.dispatch_all()
    out = coll.finalize(wh)

    # âœ… CRITICAL ASSERTIONS
    assert out["truncated"] is True or out.get("count", 0) <= cap, (
        f"âŒ CRITICAL: Collector did not truncate: count={out.get('count')} exceeds cap={cap} "
        f"(OOM vulnerability)"
    )

    if out["truncated"]:
        assert out["count"] == cap, (
            f"âŒ Truncation metadata set but count={out['count']} != cap={cap}"
        )
```

**Notes**:
- Test tries `register_collector()` if present, otherwise appends to `_collectors` (defensive)
- Uses module-level `MAX_LINKS_PER_DOC` as authoritative cap
- Verifies both `truncated` flag and actual count

---

## Test 4: Binary Search Performance (P1-1)

**File**: `tests/test_section_binary_search.py`

```python
# tests/test_section_binary_search.py
"""
Binary Search Performance Test (P1-1)

Verifies section_index_for_line() uses O(log N) binary search (per Executive summary C.2).
"""
import importlib
import pytest

def test_section_index_for_line():
    """
    Verify section_index_for_line() helper works correctly.

    Per Executive summary C.2: "section_of() must be a binary search, not linear"
    """
    try:
        wh_mod = importlib.import_module("doxstrux.markdown.utils.token_warehouse")
    except Exception:
        pytest.skip("token_warehouse module not importable")

    fn = getattr(wh_mod, "section_index_for_line", None)
    if fn is None:
        pytest.skip("section_index_for_line helper not present in token_warehouse")

    # Sections: list of (start, end) sorted by start
    sections = [
        (0, 4),
        (5, 9),
        (10, 14),
        (20, 29),
    ]

    # Test cases
    assert fn(sections, 0) == 0, "Line 0 should be in section 0"
    assert fn(sections, 4) == 0, "Line 4 should be in section 0 (end boundary)"
    assert fn(sections, 5) == 1, "Line 5 should be in section 1 (start boundary)"
    assert fn(sections, 12) == 2, "Line 12 should be in section 2"
    assert fn(sections, 19) is None, "Line 19 not in any section (gap)"
    assert fn(sections, 25) == 3, "Line 25 should be in section 3"

    # Edge cases
    assert fn([], 10) is None, "Empty sections should return None"
    assert fn(sections, -1) is None, "Negative line should return None"
    assert fn(sections, 100) is None, "Line beyond all sections should return None"
```

**Notes**:
- Tests correctness of binary search implementation
- Covers edge cases (empty sections, boundaries, gaps)
- Performance benchmarking can be added separately (see CLOSING_IMPLEMENTATION.md Part 2, P1-1)

---

## Platform Support & Test Guidance

### Running Tests Locally

```bash
# From repo root
pip install -r requirements.txt  # Ensure bleach if you want sanitization tests

# Run all new tests
pytest -q tests/test_url_normalization_parity.py \
          tests/test_html_xss_litmus.py \
          tests/test_collector_caps.py \
          tests/test_section_binary_search.py

# Individual test runs
pytest tests/test_url_normalization_parity.py -v
pytest tests/test_html_xss_litmus.py -v
pytest tests/test_collector_caps.py -v
pytest tests/test_section_binary_search.py -v
```

### Platform Notes

**Linux/macOS** (Full support):
- All tests run as expected
- SIGALRM timeout enforcement works
- Full security validation

**Windows** (Limited support):
- URL parity test may skip if fetcher normalizer not present
- Timeout-related tests not part of this patch set
- These tests are platform-independent

**CI Integration**:
- Add these tests to PR fast gate (per PART 4 of main document)
- URL parity test should be a hard fail (blocks PR merge)
- HTML litmus test should be a hard fail
- Collector caps test should be a hard fail

---

## Troubleshooting

### Problem: Import errors for modules

**Solution**: Check module paths and add to candidate lists

```python
# In test files, add your actual module paths to try_import_candidates()
security_mod = try_import_candidates([
    "security.validators",
    "your.actual.module.path",  # <-- Add your path
])
```

### Problem: Corpus file not found

**Solution**: Use absolute or relative path from project root

```bash
# Ensure adversarial corpora exist
ls adversarial_corpora/adversarial_*.json
```

### Problem: Tests skip due to missing modules

**Solution**: Install package in development mode

```bash
pip install -e ".[dev]"
```

### Problem: section_index_for_line() incompatible with your sections format

**Solution**: Adapt helper to extract start/end from your tuple shape

```python
# If your sections are (id, start, end, ...) instead of (start, end)
def section_index_for_line_adapted(sections, lineno):
    # Extract (start, end) tuples from your format
    ranges = [(s[1], s[2]) for s in sections]  # Assuming (id, start, end, ...)
    # Then use original helper logic
    ...
```

---

## References to Main Document

These patches implement:
- **P0-1**: URL Normalization Parity (Part 1, lines 63-300)
- **P0-2**: HTML/XSS Litmus (Part 1, lines 304-566)
- **P0-3**: Collector Caps (Part 1, lines 569-757)
- **P1-1**: Binary Search (Part 2, lines 1035-1136)

For complete implementation context, see:
- PART 1-3 for detailed THINKING/EXECUTION sections
- PART 4 for CI/CD integration
- PART 5 for green-light checklist
- PART 6 for rollback procedures

---

**APPENDIX END**

**Version**: 1.0 (Added 2025-10-16)
**Source**: User-provided patches
**Verification**: Aligned with Executive Summary requirements```
