{"evidence_id": "phase1_fence_regex_removal", "block_id": "phase1_fence_regex_removal", "phase": 1, "date": "2025-10-12", "file": "src/docpipe/markdown_parser_core.py", "line_before": 3583, "pattern_removed": "text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)", "replacement_strategy": "Token-based fence detection using walk_tokens_iter() and token.type == 'fence'", "code_snippet": "# Remove code blocks markers\ntext = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)\n---\n# Remove code blocks markers (Phase 1: token-based fence removal)\nif HAS_TOKEN_UTILS and walk_tokens_iter is not None:\n    # Token-based approach: parse and remove fence blocks\n    try:\n        temp_tokens = self.md.parse(text)\n        lines = text.split('\\n')\n        lines_to_remove = set()\n\n        for token in walk_tokens_iter(temp_tokens):\n            if token.type == \"fence\" and token.map:\n                start_line, end_line = token.map\n                # Mark lines for removal (fence markers + content)\n                for line_idx in range(start_line, end_line):\n                    lines_to_remove.add(line_idx)\n\n        # Remove marked lines\n        if lines_to_remove:\n            lines = [line for idx, line in enumerate(lines) if idx not in lines_to_remove]\n            text = '\\n'.join(lines)\n    except Exception:\n        # Fallback to regex if token parsing fails\n        text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)\nelse:\n    # Fallback to regex if token utilities not available\n    text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)", "test_result": "542/542 baseline tests passing", "performance_impact": "Δmedian=-15.69%, Δp95=-15.78% (improved)", "notes": "This was the only regex pattern in Phase 1 (Fences & Indented Code). Core fence/code detection was already token-based. Includes graceful fallback to regex if token utilities are unavailable.", "sha256": "58d0908b8d2300d0ed0bc4310731349f0ad5b93f3ed0ccfd5bec754d5e120f54"}
