{"evidence_id": "phase1_fence_regex_removal", "block_id": "phase1_fence_regex_removal", "phase": 1, "date": "2025-10-12", "file": "src/docpipe/markdown_parser_core.py", "line_before": 3583, "pattern_removed": "text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)", "replacement_strategy": "Token-based fence detection using walk_tokens_iter() and token.type == 'fence'", "code_snippet": "# Remove code blocks markers\ntext = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)\n---\n# Remove code blocks markers (Phase 1: token-based fence removal)\nif HAS_TOKEN_UTILS and walk_tokens_iter is not None:\n    # Token-based approach: parse and remove fence blocks\n    try:\n        temp_tokens = self.md.parse(text)\n        lines = text.split('\\n')\n        lines_to_remove = set()\n\n        for token in walk_tokens_iter(temp_tokens):\n            if token.type == \"fence\" and token.map:\n                start_line, end_line = token.map\n                # Mark lines for removal (fence markers + content)\n                for line_idx in range(start_line, end_line):\n                    lines_to_remove.add(line_idx)\n\n        # Remove marked lines\n        if lines_to_remove:\n            lines = [line for idx, line in enumerate(lines) if idx not in lines_to_remove]\n            text = '\\n'.join(lines)\n    except Exception:\n        # Fallback to regex if token parsing fails\n        text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)\nelse:\n    # Fallback to regex if token utilities not available\n    text = re.sub(r\"```[^`]*```\", \"\", text, flags=re.DOTALL)", "test_result": "542/542 baseline tests passing", "performance_impact": "Δmedian=-15.69%, Δp95=-15.78% (improved)", "notes": "This was the only regex pattern in Phase 1 (Fences & Indented Code). Core fence/code detection was already token-based. Includes graceful fallback to regex if token utilities are unavailable.", "sha256": "58d0908b8d2300d0ed0bc4310731349f0ad5b93f3ed0ccfd5bec754d5e120f54"}
{"evidence_id": "phase2-plaintext-token-impl", "phase": 2, "file": "src/docpipe/markdown_parser_core.py", "lines": "3577-3609", "description": "Token-based plaintext extraction - ZERO regex (removed fallback)", "code_snippet": "    def _strip_markdown(self, text: str) -> str:\n        \"\"\"Remove markdown formatting from text using token-based extraction.\n\n        Phase 2: Pure token-based plaintext extraction (zero regex).\n        Extracts only text content, excluding all markdown formatting:\n        - Headers, emphasis, bold, links, code blocks, inline code\n\n        Policy: Excludes code_inline content (technical content, not prose).\n        \"\"\"\n        # Token-based plaintext extraction (Phase 2 - zero regex)\n        tokens = self.md.parse(text)\n        plaintext_parts = []\n\n        for token in walk_tokens_iter(tokens):\n            if token.type == \"text\":\n                # Pure text content - include it\n                plaintext_parts.append(token.content)\n            elif token.type in (\"softbreak\", \"hardbreak\"):\n                # Convert breaks to spaces\n                plaintext_parts.append(\" \")\n            # Skip all other token types:\n            # - \"heading_open\" (header markers)\n            # - \"strong_open\"/\"em_open\" (emphasis markers)\n            # - \"code_inline\" (technical content - excluded per policy)\n            # - \"link_open\"/\"link_close\" (link markup)\n            # - \"fence\"/\"code_block\" (code blocks)\n            # We only want the text content, not the formatting\n\n        # Join and normalize whitespace\n        plaintext = \"\".join(plaintext_parts)\n        # Collapse multiple spaces and strip\n        plaintext = \" \".join(plaintext.split())\n        return plaintext", "sha256": "612a57226ad409aa396ca1698ae2a800ce3b145c6da69614521c142db913bea6", "timestamp": "2025-10-12T07:21:00.573637Z"}
